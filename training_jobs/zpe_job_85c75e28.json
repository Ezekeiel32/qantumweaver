{
  "job_id": "zpe_job_85c75e28",
  "status": "failed",
  "current_epoch": 30,
  "zpe_history": [
    {
      "epoch": 1,
      "zpe_effects": [
        0.1998872011899948,
        0.1723650097846985,
        0.10037948936223984,
        0.13880038261413574,
        0.10138120502233505,
        0.19999998807907104
      ]
    },
    {
      "epoch": 2,
      "zpe_effects": [
        0.1998872011899948,
        0.1327764242887497,
        0.07296150177717209,
        0.07016464322805405,
        0.0502723827958107,
        0.19999998807907104
      ]
    },
    {
      "epoch": 3,
      "zpe_effects": [
        0.1998872011899948,
        0.09715642780065536,
        0.058417536318302155,
        0.05080697685480118,
        0.04733676835894585,
        0.19999998807907104
      ]
    },
    {
      "epoch": 4,
      "zpe_effects": [
        0.1998872011899948,
        0.0797518864274025,
        0.03563878685235977,
        0.04824434593319893,
        0.020834017544984818,
        0.19999998807907104
      ]
    },
    {
      "epoch": 5,
      "zpe_effects": [
        0.1998872011899948,
        0.061462223529815674,
        0.0396694652736187,
        0.0393209233880043,
        0.025070548057556152,
        0.19842460751533508
      ]
    },
    {
      "epoch": 6,
      "zpe_effects": [
        0.1998872011899948,
        0.04809905216097832,
        0.032969988882541656,
        0.0310785174369812,
        0.028931712731719017,
        0.19999998807907104
      ]
    },
    {
      "epoch": 7,
      "zpe_effects": [
        0.1998872011899948,
        0.0430939681828022,
        0.025155281648039818,
        0.03946608304977417,
        0.023369206115603447,
        0.19999998807907104
      ]
    },
    {
      "epoch": 8,
      "zpe_effects": [
        0.1998872011899948,
        0.03538797050714493,
        0.021846426650881767,
        0.02079491689801216,
        0.02067427709698677,
        0.19999998807907104
      ]
    },
    {
      "epoch": 9,
      "zpe_effects": [
        0.1998872011899948,
        0.0286108385771513,
        0.013196063227951527,
        0.020058942958712578,
        0.016928112134337425,
        0.1835661679506302
      ]
    },
    {
      "epoch": 10,
      "zpe_effects": [
        0.1998872011899948,
        0.022574936971068382,
        0.01553734578192234,
        0.0196724534034729,
        0.019946444779634476,
        0.19999998807907104
      ]
    },
    {
      "epoch": 11,
      "zpe_effects": [
        0.1998872011899948,
        0.02532486990094185,
        0.01680818758904934,
        0.01699683628976345,
        0.018593454733490944,
        0.19999998807907104
      ]
    },
    {
      "epoch": 12,
      "zpe_effects": [
        0.1998872011899948,
        0.019206523895263672,
        0.013598632998764515,
        0.01545404177159071,
        0.01492244005203247,
        0.19999998807907104
      ]
    },
    {
      "epoch": 13,
      "zpe_effects": [
        0.1998872011899948,
        0.02213522233068943,
        0.01535941381007433,
        0.01747685670852661,
        0.01718764379620552,
        0.19999998807907104
      ]
    },
    {
      "epoch": 14,
      "zpe_effects": [
        0.1998872011899948,
        0.019007671624422073,
        0.012314224615693092,
        0.013715744018554688,
        0.011907815933227539,
        0.19999998807907104
      ]
    },
    {
      "epoch": 15,
      "zpe_effects": [
        0.1998872011899948,
        0.01743551529943943,
        0.009432042017579079,
        0.016758238896727562,
        0.011453724466264248,
        0.19999998807907104
      ]
    },
    {
      "epoch": 16,
      "zpe_effects": [
        0.1998872011899948,
        0.019367432221770287,
        0.0129128098487854,
        0.014454126358032227,
        0.01340099610388279,
        0.19999998807907104
      ]
    },
    {
      "epoch": 17,
      "zpe_effects": [
        0.1998872011899948,
        0.015279650688171387,
        0.010734892450273037,
        0.013786911964416504,
        0.01299583911895752,
        0.19999998807907104
      ]
    },
    {
      "epoch": 18,
      "zpe_effects": [
        0.1998872011899948,
        0.016966914758086205,
        0.011810493655502796,
        0.011106169782578945,
        0.01254504919052124,
        0.19999998807907104
      ]
    },
    {
      "epoch": 19,
      "zpe_effects": [
        0.1998872011899948,
        0.018381942063570023,
        0.010644912719726562,
        0.009201252833008766,
        0.012806248851120472,
        0.19999998807907104
      ]
    },
    {
      "epoch": 20,
      "zpe_effects": [
        0.1998872011899948,
        0.014716816134750843,
        0.009186387062072754,
        0.010520136915147305,
        0.012384939007461071,
        0.19999998807907104
      ]
    },
    {
      "epoch": 21,
      "zpe_effects": [
        0.1998872011899948,
        0.017003655433654785,
        0.009735405445098877,
        0.008220004849135876,
        0.012396002188324928,
        0.19999998807907104
      ]
    },
    {
      "epoch": 22,
      "zpe_effects": [
        0.1998872011899948,
        0.01710953749716282,
        0.011159121990203857,
        0.00893467664718628,
        0.013232695870101452,
        0.19999998807907104
      ]
    },
    {
      "epoch": 23,
      "zpe_effects": [
        0.1998872011899948,
        0.01744063012301922,
        0.010414361953735352,
        0.008915424346923828,
        0.012762046419084072,
        0.19999998807907104
      ]
    },
    {
      "epoch": 24,
      "zpe_effects": [
        0.1998872011899948,
        0.016709674149751663,
        0.009432769380509853,
        0.008941817097365856,
        0.0124802952632308,
        0.19999998807907104
      ]
    },
    {
      "epoch": 25,
      "zpe_effects": [
        0.1998872011899948,
        0.017855430021882057,
        0.010035253129899502,
        0.00897073745727539,
        0.013081527315080166,
        0.19999998807907104
      ]
    },
    {
      "epoch": 26,
      "zpe_effects": [
        0.1998872011899948,
        0.016627538949251175,
        0.009814823046326637,
        0.008654105477035046,
        0.012410843744874,
        0.19999998807907104
      ]
    },
    {
      "epoch": 27,
      "zpe_effects": [
        0.1998872011899948,
        0.013469613157212734,
        0.007929110899567604,
        0.007912385277450085,
        0.011507022194564342,
        0.19999998807907104
      ]
    },
    {
      "epoch": 28,
      "zpe_effects": [
        0.1998872011899948,
        0.014857363887131214,
        0.009136212058365345,
        0.008640778250992298,
        0.012388634495437145,
        0.19999998807907104
      ]
    },
    {
      "epoch": 29,
      "zpe_effects": [
        0.1998872011899948,
        0.016853714361786842,
        0.010254479013383389,
        0.009327125735580921,
        0.012831950560212135,
        0.19999998807907104
      ]
    },
    {
      "epoch": 30,
      "zpe_effects": [
        0.1998872011899948,
        0.015729129314422607,
        0.009737920947372913,
        0.008430051617324352,
        0.01201776321977377,
        0.19999998807907104
      ]
    }
  ],
  "total_epochs": 30,
  "accuracy": 99.65,
  "loss": 0.513688287795923,
  "zpe_effects": [
    0.1998872011899948,
    0.015729129314422607,
    0.009737920947372913,
    0.008430051617324352,
    0.01201776321977377,
    0.19999998807907104
  ],
  "log_messages": [
    "Init job: ZPE-QuantumWeaver-V1",
    "Starting PyTorch training: ZPE-QuantumWeaver-V1",
    "Device: cuda",
    "Setting up MNIST dataset...",
    "DataLoaders created. Train: 1875, Val: 313 batches.",
    "Model & Optimizer initialized.",
    "--- Epoch 1/30 ---",
    "E1 B375/1875 L: 0.7341",
    "E1 B750/1875 L: 0.7981",
    "E1 B1125/1875 L: 1.1479",
    "E1 B1500/1875 L: 1.4602",
    "E1 END - TrainL: 1.1894, ValAcc: 98.99%, ValL: 0.5572",
    "ZPE: ['0.1999', '0.1724', '0.1004', '0.1388', '0.1014', '0.2000']",
    "--- Epoch 2/30 ---",
    "E2 B375/1875 L: 0.8498",
    "E2 B750/1875 L: 0.9048",
    "E2 B1125/1875 L: 0.6893",
    "E2 B1500/1875 L: 1.6373",
    "E2 END - TrainL: 1.0600, ValAcc: 98.80%, ValL: 0.5882",
    "ZPE: ['0.1999', '0.1328', '0.0730', '0.0702', '0.0503', '0.2000']",
    "--- Epoch 3/30 ---",
    "E3 B375/1875 L: 1.5232",
    "E3 B750/1875 L: 0.8727",
    "E3 B1125/1875 L: 0.6606",
    "E3 B1500/1875 L: 0.8432",
    "E3 END - TrainL: 1.0377, ValAcc: 99.18%, ValL: 0.5432",
    "ZPE: ['0.1999', '0.0972', '0.0584', '0.0508', '0.0473', '0.2000']",
    "--- Epoch 4/30 ---",
    "E4 B375/1875 L: 1.5979",
    "E4 B750/1875 L: 1.4753",
    "E4 B1125/1875 L: 0.6206",
    "E4 B1500/1875 L: 0.7712",
    "E4 END - TrainL: 1.0116, ValAcc: 98.92%, ValL: 0.5506",
    "ZPE: ['0.1999', '0.0798', '0.0356', '0.0482', '0.0208', '0.2000']",
    "--- Epoch 5/30 ---",
    "E5 B375/1875 L: 1.4947",
    "E5 B750/1875 L: 1.5152",
    "E5 B1125/1875 L: 1.0272",
    "E5 B1500/1875 L: 1.5618",
    "E5 END - TrainL: 0.9933, ValAcc: 98.96%, ValL: 0.5752",
    "ZPE: ['0.1999', '0.0615', '0.0397', '0.0393', '0.0251', '0.1984']",
    "--- Epoch 6/30 ---",
    "E6 B375/1875 L: 1.4236",
    "E6 B750/1875 L: 0.6789",
    "E6 B1125/1875 L: 0.9309",
    "E6 B1500/1875 L: 0.8712",
    "E6 END - TrainL: 0.9839, ValAcc: 98.85%, ValL: 0.5537",
    "ZPE: ['0.1999', '0.0481', '0.0330', '0.0311', '0.0289', '0.2000']",
    "--- Epoch 7/30 ---",
    "E7 B375/1875 L: 0.9981",
    "E7 B750/1875 L: 0.5715",
    "E7 B1125/1875 L: 0.7329",
    "E7 B1500/1875 L: 0.5613",
    "E7 END - TrainL: 0.9921, ValAcc: 99.20%, ValL: 0.5550",
    "ZPE: ['0.1999', '0.0431', '0.0252', '0.0395', '0.0234', '0.2000']",
    "--- Epoch 8/30 ---",
    "E8 B375/1875 L: 0.6037",
    "E8 B750/1875 L: 0.7889",
    "E8 B1125/1875 L: 1.0517",
    "E8 B1500/1875 L: 0.7168",
    "E8 END - TrainL: 0.9582, ValAcc: 99.21%, ValL: 0.5487",
    "ZPE: ['0.1999', '0.0354', '0.0218', '0.0208', '0.0207', '0.2000']",
    "--- Epoch 9/30 ---",
    "E9 B375/1875 L: 1.1147",
    "E9 B750/1875 L: 0.8669",
    "E9 B1125/1875 L: 0.8826",
    "E9 B1500/1875 L: 1.1901",
    "E9 END - TrainL: 0.9571, ValAcc: 98.72%, ValL: 0.5960",
    "ZPE: ['0.1999', '0.0286', '0.0132', '0.0201', '0.0169', '0.1836']",
    "--- Epoch 10/30 ---",
    "E10 B375/1875 L: 0.5401",
    "E10 B750/1875 L: 1.1469",
    "E10 B1125/1875 L: 0.5848",
    "E10 B1500/1875 L: 1.2422",
    "E10 END - TrainL: 0.9336, ValAcc: 99.07%, ValL: 0.5327",
    "ZPE: ['0.1999', '0.0226', '0.0155', '0.0197', '0.0199', '0.2000']",
    "--- Epoch 11/30 ---",
    "E11 B375/1875 L: 0.5981",
    "E11 B750/1875 L: 1.4104",
    "E11 B1125/1875 L: 0.6196",
    "E11 B1500/1875 L: 1.4950",
    "E11 END - TrainL: 0.9241, ValAcc: 99.31%, ValL: 0.5459",
    "ZPE: ['0.1999', '0.0253', '0.0168', '0.0170', '0.0186', '0.2000']",
    "--- Epoch 12/30 ---",
    "E12 B375/1875 L: 0.8433",
    "E12 B750/1875 L: 0.9126",
    "E12 B1125/1875 L: 0.7723",
    "E12 B1500/1875 L: 1.0243",
    "E12 END - TrainL: 0.9235, ValAcc: 99.24%, ValL: 0.5305",
    "ZPE: ['0.1999', '0.0192', '0.0136', '0.0155', '0.0149', '0.2000']",
    "--- Epoch 13/30 ---",
    "E13 B375/1875 L: 1.2583",
    "E13 B750/1875 L: 0.6815",
    "E13 B1125/1875 L: 0.6174",
    "E13 B1500/1875 L: 0.8980",
    "E13 END - TrainL: 0.9043, ValAcc: 99.39%, ValL: 0.5374",
    "ZPE: ['0.1999', '0.0221', '0.0154', '0.0175', '0.0172', '0.2000']",
    "--- Epoch 14/30 ---",
    "E14 B375/1875 L: 0.5387",
    "E14 B750/1875 L: 1.0678",
    "E14 B1125/1875 L: 0.5498",
    "E14 B1500/1875 L: 0.6314",
    "E14 END - TrainL: 0.8948, ValAcc: 99.36%, ValL: 0.5342",
    "ZPE: ['0.1999', '0.0190', '0.0123', '0.0137', '0.0119', '0.2000']",
    "--- Epoch 15/30 ---",
    "E15 B375/1875 L: 0.6807",
    "E15 B750/1875 L: 0.6311",
    "E15 B1125/1875 L: 0.6224",
    "E15 B1500/1875 L: 0.9298",
    "E15 END - TrainL: 0.9082, ValAcc: 99.44%, ValL: 0.5248",
    "ZPE: ['0.1999', '0.0174', '0.0094', '0.0168', '0.0115', '0.2000']",
    "--- Epoch 16/30 ---",
    "E16 B375/1875 L: 1.3849",
    "E16 B750/1875 L: 0.5881",
    "E16 B1125/1875 L: 0.9092",
    "E16 B1500/1875 L: 1.2311",
    "E16 END - TrainL: 0.8876, ValAcc: 99.54%, ValL: 0.5273",
    "ZPE: ['0.1999', '0.0194', '0.0129', '0.0145', '0.0134', '0.2000']",
    "--- Epoch 17/30 ---",
    "E17 B375/1875 L: 0.5220",
    "E17 B750/1875 L: 0.9710",
    "E17 B1125/1875 L: 1.0634",
    "E17 B1500/1875 L: 1.1464",
    "E17 END - TrainL: 0.8696, ValAcc: 99.45%, ValL: 0.5233",
    "ZPE: ['0.1999', '0.0153', '0.0107', '0.0138', '0.0130', '0.2000']",
    "--- Epoch 18/30 ---",
    "E18 B375/1875 L: 0.8361",
    "E18 B750/1875 L: 0.6445",
    "E18 B1125/1875 L: 1.2650",
    "E18 B1500/1875 L: 0.8048",
    "E18 END - TrainL: 0.8782, ValAcc: 99.53%, ValL: 0.5258",
    "ZPE: ['0.1999', '0.0170', '0.0118', '0.0111', '0.0125', '0.2000']",
    "--- Epoch 19/30 ---",
    "E19 B375/1875 L: 0.7261",
    "E19 B750/1875 L: 0.7272",
    "E19 B1125/1875 L: 0.9404",
    "E19 B1500/1875 L: 0.5696",
    "E19 END - TrainL: 0.8591, ValAcc: 99.41%, ValL: 0.5251",
    "ZPE: ['0.1999', '0.0184', '0.0106', '0.0092', '0.0128', '0.2000']",
    "--- Epoch 20/30 ---",
    "E20 B375/1875 L: 0.8407",
    "E20 B750/1875 L: 1.1758",
    "E20 B1125/1875 L: 1.2978",
    "E20 B1500/1875 L: 0.9858",
    "E20 END - TrainL: 0.8583, ValAcc: 99.56%, ValL: 0.5213",
    "ZPE: ['0.1999', '0.0147', '0.0092', '0.0105', '0.0124', '0.2000']",
    "--- Epoch 21/30 ---",
    "E21 B375/1875 L: 0.7745",
    "E21 B750/1875 L: 0.5722",
    "E21 B1125/1875 L: 1.1656",
    "E21 B1500/1875 L: 0.8570",
    "E21 END - TrainL: 0.8597, ValAcc: 99.54%, ValL: 0.5175",
    "ZPE: ['0.1999', '0.0170', '0.0097', '0.0082', '0.0124', '0.2000']",
    "--- Epoch 22/30 ---",
    "E22 B375/1875 L: 1.0446",
    "E22 B750/1875 L: 1.0929",
    "E22 B1125/1875 L: 0.5128",
    "E22 B1500/1875 L: 0.5346",
    "E22 END - TrainL: 0.8568, ValAcc: 99.53%, ValL: 0.5172",
    "ZPE: ['0.1999', '0.0171', '0.0112', '0.0089', '0.0132', '0.2000']",
    "--- Epoch 23/30 ---",
    "E23 B375/1875 L: 0.6093",
    "E23 B750/1875 L: 0.7792",
    "E23 B1125/1875 L: 0.5359",
    "E23 B1500/1875 L: 0.7857",
    "E23 END - TrainL: 0.8359, ValAcc: 99.50%, ValL: 0.5184",
    "ZPE: ['0.1999', '0.0174', '0.0104', '0.0089', '0.0128', '0.2000']",
    "--- Epoch 24/30 ---",
    "E24 B375/1875 L: 0.5721",
    "E24 B750/1875 L: 1.0556",
    "E24 B1125/1875 L: 0.6352",
    "E24 B1500/1875 L: 0.5258",
    "E24 END - TrainL: 0.8368, ValAcc: 99.52%, ValL: 0.5202",
    "ZPE: ['0.1999', '0.0167', '0.0094', '0.0089', '0.0125', '0.2000']",
    "--- Epoch 25/30 ---",
    "E25 B375/1875 L: 1.1705",
    "E25 B750/1875 L: 1.2993",
    "E25 B1125/1875 L: 1.1139",
    "E25 B1500/1875 L: 0.6750",
    "E25 END - TrainL: 0.8362, ValAcc: 99.61%, ValL: 0.5158",
    "ZPE: ['0.1999', '0.0179', '0.0100', '0.0090', '0.0131', '0.2000']",
    "--- Epoch 26/30 ---",
    "E26 B375/1875 L: 1.1572",
    "E26 B750/1875 L: 1.0913",
    "E26 B1125/1875 L: 0.6264",
    "E26 B1500/1875 L: 0.5866",
    "E26 END - TrainL: 0.8431, ValAcc: 99.64%, ValL: 0.5161",
    "ZPE: ['0.1999', '0.0166', '0.0098', '0.0087', '0.0124', '0.2000']",
    "--- Epoch 27/30 ---",
    "E27 B375/1875 L: 0.8199",
    "E27 B750/1875 L: 0.5439",
    "E27 B1125/1875 L: 0.9273",
    "E27 B1500/1875 L: 0.9083",
    "E27 END - TrainL: 0.8253, ValAcc: 99.63%, ValL: 0.5154",
    "ZPE: ['0.1999', '0.0135', '0.0079', '0.0079', '0.0115', '0.2000']",
    "--- Epoch 28/30 ---",
    "E28 B375/1875 L: 0.9514",
    "E28 B750/1875 L: 1.5434",
    "E28 B1125/1875 L: 0.6291",
    "E28 B1500/1875 L: 0.9164",
    "E28 END - TrainL: 0.8209, ValAcc: 99.63%, ValL: 0.5137",
    "ZPE: ['0.1999', '0.0149', '0.0091', '0.0086', '0.0124', '0.2000']",
    "--- Epoch 29/30 ---",
    "E29 B375/1875 L: 0.5588",
    "E29 B750/1875 L: 0.8578",
    "E29 B1125/1875 L: 0.9893",
    "E29 B1500/1875 L: 1.2643",
    "E29 END - TrainL: 0.8273, ValAcc: 99.61%, ValL: 0.5145",
    "ZPE: ['0.1999', '0.0169', '0.0103', '0.0093', '0.0128', '0.2000']",
    "--- Epoch 30/30 ---",
    "E30 B375/1875 L: 0.5107",
    "E30 B750/1875 L: 0.9571",
    "E30 B1125/1875 L: 1.3024",
    "E30 B1500/1875 L: 0.7836",
    "E30 END - TrainL: 0.8289, ValAcc: 99.65%, ValL: 0.5137",
    "ZPE: ['0.1999', '0.0157', '0.0097', '0.0084', '0.0120', '0.2000']",
    "Training done! Final Val Acc: 99.65%",
    "Model saved: training_jobs/zpe_job_85c75e28_model.pth",
    "Train Error job zpe_job_85c75e28: TrainingLogger.log_job_completion() missing 2 required positional arguments: 'final_accuracy' and 'final_loss'",
    "Traceback (most recent call last):\n  File \"/home/chezy/Desktop/cursor/qantumweaver/app.py\", line 611, in run_training_job\n    training_logger.log_job_completion(job_status['job_id'], job_status['accuracy'], job_status['loss'])\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: TrainingLogger.log_job_completion() missing 2 required positional arguments: 'final_accuracy' and 'final_loss'\n"
  ],
  "parameters": {
    "totalEpochs": 30,
    "batchSize": 32,
    "learningRate": 0.001,
    "weightDecay": 0.0001,
    "momentumParams": [
      0.9,
      0.9,
      0.9,
      0.9,
      0.9,
      0.9
    ],
    "strengthParams": [
      0.1,
      0.1,
      0.1,
      0.1,
      0.1,
      0.1
    ],
    "noiseParams": [
      0.01,
      0.01,
      0.01,
      0.01,
      0.01,
      0.01
    ],
    "couplingParams": [
      0.1,
      0.1,
      0.1,
      0.1,
      0.1,
      0.1
    ],
    "quantumCircuitSize": 32,
    "labelSmoothing": 0.1,
    "quantumMode": true,
    "modelName": "ZPE-QuantumWeaver-V1",
    "baseConfigId": null
  },
  "start_time": "2025-06-17T20:40:39.470045",
  "end_time": "2025-06-17T21:39:05.330730",
  "gpu_info": {
    "id": "0",
    "name": "NVIDIA GeForce RTX 3050 6GB Laptop GPU",
    "utilization_gpu_percent": 95.0,
    "utilization_memory_io_percent": 90.0,
    "memory_total_mb": 6144.0,
    "memory_used_mb": 624.875,
    "memory_free_mb": 5519.125,
    "memory_used_percent": 10.170491536458334,
    "temperature_c": 65.0,
    "power_draw_w": 20.0,
    "fan_speed_percent": null
  }
}