{
  "job_id": "zpe_job_0694cff4",
  "status": "completed",
  "parameters": {
    "modelName": "ZPE-QuantumWeaver-V1",
    "totalEpochs": 20,
    "batchSize": 32,
    "learningRate": 0.0011,
    "weightDecay": 0.0001,
    "momentumParams": [
      0.91,
      0.91,
      0.91,
      0.91,
      0.91,
      0.91
    ],
    "strengthParams": [
      0.09,
      0.09,
      0.09,
      0.09,
      0.09,
      0.09
    ],
    "noiseParams": [
      0.011,
      0.011,
      0.011,
      0.011,
      0.011,
      0.011
    ],
    "couplingParams": [
      0.11,
      0.11,
      0.11,
      0.11,
      0.11,
      0.08
    ],
    "quantumCircuitSize": 32,
    "labelSmoothing": 0.1,
    "quantumMode": true,
    "baseConfigId": "zpe_job_d243fa84",
    "mixupAlpha": 0.2
  },
  "start_time": "2025-06-20T05:33:56.617Z",
  "log_messages": [
    "Using device: cuda",
    "Datasets loaded successfully",
    "Model initialized",
    "Epoch 1/20 - Batch 0/1875 - Loss: 2.3052",
    "Epoch 1/20 - Batch 100/1875 - Loss: 0.5626",
    "Epoch 1/20 - Batch 200/1875 - Loss: 0.5412",
    "Epoch 1/20 - Batch 300/1875 - Loss: 0.2344",
    "Epoch 1/20 - Batch 400/1875 - Loss: 0.2038",
    "Epoch 1/20 - Batch 500/1875 - Loss: 0.2965",
    "Epoch 1/20 - Batch 600/1875 - Loss: 0.2012",
    "Epoch 1/20 - Batch 700/1875 - Loss: 0.1761",
    "Epoch 1/20 - Batch 800/1875 - Loss: 0.0123",
    "Epoch 1/20 - Batch 900/1875 - Loss: 0.2582",
    "Epoch 1/20 - Batch 1000/1875 - Loss: 0.0360",
    "Epoch 1/20 - Batch 1100/1875 - Loss: 0.2867",
    "Epoch 1/20 - Batch 1200/1875 - Loss: 0.1615",
    "Epoch 1/20 - Batch 1300/1875 - Loss: 0.1963",
    "Epoch 1/20 - Batch 1400/1875 - Loss: 0.1597",
    "Epoch 1/20 - Batch 1500/1875 - Loss: 0.1478",
    "Epoch 1/20 - Batch 1600/1875 - Loss: 0.1571",
    "Epoch 1/20 - Batch 1700/1875 - Loss: 0.0471",
    "Epoch 1/20 - Batch 1800/1875 - Loss: 0.3362",
    "Epoch 1 completed - Train Acc: 91.60% - Val Acc: 95.93%",
    "Epoch 2/20 - Batch 0/1875 - Loss: 0.0979",
    "Epoch 2/20 - Batch 100/1875 - Loss: 0.2110",
    "Epoch 2/20 - Batch 200/1875 - Loss: 0.1936",
    "Epoch 2/20 - Batch 300/1875 - Loss: 0.1562",
    "Epoch 2/20 - Batch 400/1875 - Loss: 0.1031",
    "Epoch 2/20 - Batch 500/1875 - Loss: 0.1576",
    "Epoch 2/20 - Batch 600/1875 - Loss: 0.1836",
    "Epoch 2/20 - Batch 700/1875 - Loss: 0.0228",
    "Epoch 2/20 - Batch 800/1875 - Loss: 0.1462",
    "Epoch 2/20 - Batch 900/1875 - Loss: 0.0947",
    "Epoch 2/20 - Batch 1000/1875 - Loss: 0.0055",
    "Epoch 2/20 - Batch 1100/1875 - Loss: 0.1760",
    "Epoch 2/20 - Batch 1200/1875 - Loss: 0.1469",
    "Epoch 2/20 - Batch 1300/1875 - Loss: 0.0854",
    "Epoch 2/20 - Batch 1400/1875 - Loss: 0.0804",
    "Epoch 2/20 - Batch 1500/1875 - Loss: 0.0878",
    "Epoch 2/20 - Batch 1600/1875 - Loss: 0.1407",
    "Epoch 2/20 - Batch 1700/1875 - Loss: 0.0310",
    "Epoch 2/20 - Batch 1800/1875 - Loss: 0.2410",
    "Epoch 2 completed - Train Acc: 96.39% - Val Acc: 96.42%",
    "Epoch 3/20 - Batch 0/1875 - Loss: 0.0171",
    "Epoch 3/20 - Batch 100/1875 - Loss: 0.0420",
    "Epoch 3/20 - Batch 200/1875 - Loss: 0.1296",
    "Epoch 3/20 - Batch 300/1875 - Loss: 0.2085",
    "Epoch 3/20 - Batch 400/1875 - Loss: 0.1028",
    "Epoch 3/20 - Batch 500/1875 - Loss: 0.0427",
    "Epoch 3/20 - Batch 600/1875 - Loss: 0.0394",
    "Epoch 3/20 - Batch 700/1875 - Loss: 0.0734",
    "Epoch 3/20 - Batch 800/1875 - Loss: 0.0394",
    "Epoch 3/20 - Batch 900/1875 - Loss: 0.0300",
    "Epoch 3/20 - Batch 1000/1875 - Loss: 0.0509",
    "Epoch 3/20 - Batch 1100/1875 - Loss: 0.0217",
    "Epoch 3/20 - Batch 1200/1875 - Loss: 0.0125",
    "Epoch 3/20 - Batch 1300/1875 - Loss: 0.2660",
    "Epoch 3/20 - Batch 1400/1875 - Loss: 0.0377",
    "Epoch 3/20 - Batch 1500/1875 - Loss: 0.3046",
    "Epoch 3/20 - Batch 1600/1875 - Loss: 0.0694",
    "Epoch 3/20 - Batch 1700/1875 - Loss: 0.1082",
    "Epoch 3/20 - Batch 1800/1875 - Loss: 0.0360",
    "Epoch 3 completed - Train Acc: 97.17% - Val Acc: 97.69%",
    "Epoch 4/20 - Batch 0/1875 - Loss: 0.1472",
    "Epoch 4/20 - Batch 100/1875 - Loss: 0.0112",
    "Epoch 4/20 - Batch 200/1875 - Loss: 0.1537",
    "Epoch 4/20 - Batch 300/1875 - Loss: 0.2342",
    "Epoch 4/20 - Batch 400/1875 - Loss: 0.0017",
    "Epoch 4/20 - Batch 500/1875 - Loss: 0.0675",
    "Epoch 4/20 - Batch 600/1875 - Loss: 0.0997",
    "Epoch 4/20 - Batch 700/1875 - Loss: 0.0351",
    "Epoch 4/20 - Batch 800/1875 - Loss: 0.1750",
    "Epoch 4/20 - Batch 900/1875 - Loss: 0.0253",
    "Epoch 4/20 - Batch 1000/1875 - Loss: 0.0422",
    "Epoch 4/20 - Batch 1100/1875 - Loss: 0.0053",
    "Epoch 4/20 - Batch 1200/1875 - Loss: 0.0027",
    "Epoch 4/20 - Batch 1300/1875 - Loss: 0.0468",
    "Epoch 4/20 - Batch 1400/1875 - Loss: 0.1642",
    "Epoch 4/20 - Batch 1500/1875 - Loss: 0.0289",
    "Epoch 4/20 - Batch 1600/1875 - Loss: 0.0946",
    "Epoch 4/20 - Batch 1700/1875 - Loss: 0.2315",
    "Epoch 4/20 - Batch 1800/1875 - Loss: 0.0769",
    "Epoch 4 completed - Train Acc: 97.64% - Val Acc: 97.49%",
    "Epoch 5/20 - Batch 0/1875 - Loss: 0.0034",
    "Epoch 5/20 - Batch 100/1875 - Loss: 0.1646",
    "Epoch 5/20 - Batch 200/1875 - Loss: 0.0088",
    "Epoch 5/20 - Batch 300/1875 - Loss: 0.0315",
    "Epoch 5/20 - Batch 400/1875 - Loss: 0.2240",
    "Epoch 5/20 - Batch 500/1875 - Loss: 0.1329",
    "Epoch 5/20 - Batch 600/1875 - Loss: 0.0283",
    "Epoch 5/20 - Batch 700/1875 - Loss: 0.0076",
    "Epoch 5/20 - Batch 800/1875 - Loss: 0.0617",
    "Epoch 5/20 - Batch 900/1875 - Loss: 0.0530",
    "Epoch 5/20 - Batch 1000/1875 - Loss: 0.0402",
    "Epoch 5/20 - Batch 1100/1875 - Loss: 0.0025",
    "Epoch 5/20 - Batch 1200/1875 - Loss: 0.0372",
    "Epoch 5/20 - Batch 1300/1875 - Loss: 0.0163",
    "Epoch 5/20 - Batch 1400/1875 - Loss: 0.0517",
    "Epoch 5/20 - Batch 1500/1875 - Loss: 0.0125",
    "Epoch 5/20 - Batch 1600/1875 - Loss: 0.0690",
    "Epoch 5/20 - Batch 1700/1875 - Loss: 0.0483",
    "Epoch 5/20 - Batch 1800/1875 - Loss: 0.0712",
    "Epoch 5 completed - Train Acc: 97.99% - Val Acc: 97.59%",
    "Epoch 6/20 - Batch 0/1875 - Loss: 0.0021",
    "Epoch 6/20 - Batch 100/1875 - Loss: 0.0449",
    "Epoch 6/20 - Batch 200/1875 - Loss: 0.0211",
    "Epoch 6/20 - Batch 300/1875 - Loss: 0.0236",
    "Epoch 6/20 - Batch 400/1875 - Loss: 0.0034",
    "Epoch 6/20 - Batch 500/1875 - Loss: 0.2495",
    "Epoch 6/20 - Batch 600/1875 - Loss: 0.0130",
    "Epoch 6/20 - Batch 700/1875 - Loss: 0.0820",
    "Epoch 6/20 - Batch 800/1875 - Loss: 0.0034",
    "Epoch 6/20 - Batch 900/1875 - Loss: 0.0442",
    "Epoch 6/20 - Batch 1000/1875 - Loss: 0.0008",
    "Epoch 6/20 - Batch 1100/1875 - Loss: 0.0699",
    "Epoch 6/20 - Batch 1200/1875 - Loss: 0.1120",
    "Epoch 6/20 - Batch 1300/1875 - Loss: 0.0070",
    "Epoch 6/20 - Batch 1400/1875 - Loss: 0.0365",
    "Epoch 6/20 - Batch 1500/1875 - Loss: 0.0062",
    "Epoch 6/20 - Batch 1600/1875 - Loss: 0.1194",
    "Epoch 6/20 - Batch 1700/1875 - Loss: 0.0047",
    "Epoch 6/20 - Batch 1800/1875 - Loss: 0.0032",
    "Epoch 6 completed - Train Acc: 98.19% - Val Acc: 97.05%",
    "Epoch 7/20 - Batch 0/1875 - Loss: 0.1529",
    "Epoch 7/20 - Batch 100/1875 - Loss: 0.0195",
    "Epoch 7/20 - Batch 200/1875 - Loss: 0.0079",
    "Epoch 7/20 - Batch 300/1875 - Loss: 0.0103",
    "Epoch 7/20 - Batch 400/1875 - Loss: 0.0122",
    "Epoch 7/20 - Batch 500/1875 - Loss: 0.0106",
    "Epoch 7/20 - Batch 600/1875 - Loss: 0.0222",
    "Epoch 7/20 - Batch 700/1875 - Loss: 0.0114",
    "Epoch 7/20 - Batch 800/1875 - Loss: 0.0197",
    "Epoch 7/20 - Batch 900/1875 - Loss: 0.0054",
    "Epoch 7/20 - Batch 1000/1875 - Loss: 0.0453",
    "Epoch 7/20 - Batch 1100/1875 - Loss: 0.0012",
    "Epoch 7/20 - Batch 1200/1875 - Loss: 0.0067",
    "Epoch 7/20 - Batch 1300/1875 - Loss: 0.0008",
    "Epoch 7/20 - Batch 1400/1875 - Loss: 0.0192",
    "Epoch 7/20 - Batch 1500/1875 - Loss: 0.2822",
    "Epoch 7/20 - Batch 1600/1875 - Loss: 0.0125",
    "Epoch 7/20 - Batch 1700/1875 - Loss: 0.0193",
    "Epoch 7/20 - Batch 1800/1875 - Loss: 0.1116",
    "Epoch 7 completed - Train Acc: 98.16% - Val Acc: 97.68%",
    "Epoch 8/20 - Batch 0/1875 - Loss: 0.1507",
    "Epoch 8/20 - Batch 100/1875 - Loss: 0.1031",
    "Epoch 8/20 - Batch 200/1875 - Loss: 0.1087",
    "Epoch 8/20 - Batch 300/1875 - Loss: 0.0030",
    "Epoch 8/20 - Batch 400/1875 - Loss: 0.1655",
    "Epoch 8/20 - Batch 500/1875 - Loss: 0.0868",
    "Epoch 8/20 - Batch 600/1875 - Loss: 0.0285",
    "Epoch 8/20 - Batch 700/1875 - Loss: 0.0025",
    "Epoch 8/20 - Batch 800/1875 - Loss: 0.0507",
    "Epoch 8/20 - Batch 900/1875 - Loss: 0.0487",
    "Epoch 8/20 - Batch 1000/1875 - Loss: 0.3342",
    "Epoch 8/20 - Batch 1100/1875 - Loss: 0.0596",
    "Epoch 8/20 - Batch 1200/1875 - Loss: 0.0028",
    "Epoch 8/20 - Batch 1300/1875 - Loss: 0.0344",
    "Epoch 8/20 - Batch 1400/1875 - Loss: 0.0472",
    "Epoch 8/20 - Batch 1500/1875 - Loss: 0.0641",
    "Epoch 8/20 - Batch 1600/1875 - Loss: 0.0470",
    "Epoch 8/20 - Batch 1700/1875 - Loss: 0.0045",
    "Epoch 8/20 - Batch 1800/1875 - Loss: 0.0127",
    "Epoch 8 completed - Train Acc: 98.43% - Val Acc: 97.46%",
    "Epoch 9/20 - Batch 0/1875 - Loss: 0.0584",
    "Epoch 9/20 - Batch 100/1875 - Loss: 0.0503",
    "Epoch 9/20 - Batch 200/1875 - Loss: 0.0006",
    "Epoch 9/20 - Batch 300/1875 - Loss: 0.0067",
    "Epoch 9/20 - Batch 400/1875 - Loss: 0.0268",
    "Epoch 9/20 - Batch 500/1875 - Loss: 0.0212",
    "Epoch 9/20 - Batch 600/1875 - Loss: 0.0967",
    "Epoch 9/20 - Batch 700/1875 - Loss: 0.0542",
    "Epoch 9/20 - Batch 800/1875 - Loss: 0.0009",
    "Epoch 9/20 - Batch 900/1875 - Loss: 0.0031",
    "Epoch 9/20 - Batch 1000/1875 - Loss: 0.0060",
    "Epoch 9/20 - Batch 1100/1875 - Loss: 0.0715",
    "Epoch 9/20 - Batch 1200/1875 - Loss: 0.0201",
    "Epoch 9/20 - Batch 1300/1875 - Loss: 0.5000",
    "Epoch 9/20 - Batch 1400/1875 - Loss: 0.0456",
    "Epoch 9/20 - Batch 1500/1875 - Loss: 0.0169",
    "Epoch 9/20 - Batch 1600/1875 - Loss: 0.3684",
    "Epoch 9/20 - Batch 1700/1875 - Loss: 0.0099",
    "Epoch 9/20 - Batch 1800/1875 - Loss: 0.0002",
    "Epoch 9 completed - Train Acc: 98.54% - Val Acc: 97.79%",
    "Epoch 10/20 - Batch 0/1875 - Loss: 0.0061",
    "Epoch 10/20 - Batch 100/1875 - Loss: 0.1345",
    "Epoch 10/20 - Batch 200/1875 - Loss: 0.0028",
    "Epoch 10/20 - Batch 300/1875 - Loss: 0.0029",
    "Epoch 10/20 - Batch 400/1875 - Loss: 0.0006",
    "Epoch 10/20 - Batch 500/1875 - Loss: 0.0250",
    "Epoch 10/20 - Batch 600/1875 - Loss: 0.0177",
    "Epoch 10/20 - Batch 700/1875 - Loss: 0.0246",
    "Epoch 10/20 - Batch 800/1875 - Loss: 0.0005",
    "Epoch 10/20 - Batch 900/1875 - Loss: 0.0022",
    "Epoch 10/20 - Batch 1000/1875 - Loss: 0.0014",
    "Epoch 10/20 - Batch 1100/1875 - Loss: 0.0237",
    "Epoch 10/20 - Batch 1200/1875 - Loss: 0.0182",
    "Epoch 10/20 - Batch 1300/1875 - Loss: 0.0005",
    "Epoch 10/20 - Batch 1400/1875 - Loss: 0.0020",
    "Epoch 10/20 - Batch 1500/1875 - Loss: 0.1640",
    "Epoch 10/20 - Batch 1600/1875 - Loss: 0.1181",
    "Epoch 10/20 - Batch 1700/1875 - Loss: 0.0019",
    "Epoch 10/20 - Batch 1800/1875 - Loss: 0.0011",
    "Epoch 10 completed - Train Acc: 98.57% - Val Acc: 97.41%",
    "Epoch 11/20 - Batch 0/1875 - Loss: 0.0028",
    "Epoch 11/20 - Batch 100/1875 - Loss: 0.0010",
    "Epoch 11/20 - Batch 200/1875 - Loss: 0.0118",
    "Epoch 11/20 - Batch 300/1875 - Loss: 0.1362",
    "Epoch 11/20 - Batch 400/1875 - Loss: 0.0056",
    "Epoch 11/20 - Batch 500/1875 - Loss: 0.0531",
    "Epoch 11/20 - Batch 600/1875 - Loss: 0.0448",
    "Epoch 11/20 - Batch 700/1875 - Loss: 0.0005",
    "Epoch 11/20 - Batch 800/1875 - Loss: 0.0690",
    "Epoch 11/20 - Batch 900/1875 - Loss: 0.0491",
    "Epoch 11/20 - Batch 1000/1875 - Loss: 0.0039",
    "Epoch 11/20 - Batch 1100/1875 - Loss: 0.0243",
    "Epoch 11/20 - Batch 1200/1875 - Loss: 0.0007",
    "Epoch 11/20 - Batch 1300/1875 - Loss: 0.1537",
    "Epoch 11/20 - Batch 1400/1875 - Loss: 0.0287",
    "Epoch 11/20 - Batch 1500/1875 - Loss: 0.0700",
    "Epoch 11/20 - Batch 1600/1875 - Loss: 0.0086",
    "Epoch 11/20 - Batch 1700/1875 - Loss: 0.0294",
    "Epoch 11/20 - Batch 1800/1875 - Loss: 0.0249",
    "Epoch 11 completed - Train Acc: 98.66% - Val Acc: 97.67%",
    "Epoch 12/20 - Batch 0/1875 - Loss: 0.0004",
    "Epoch 12/20 - Batch 100/1875 - Loss: 0.0071",
    "Epoch 12/20 - Batch 200/1875 - Loss: 0.0313",
    "Epoch 12/20 - Batch 300/1875 - Loss: 0.0012",
    "Epoch 12/20 - Batch 400/1875 - Loss: 0.1120",
    "Epoch 12/20 - Batch 500/1875 - Loss: 0.0019",
    "Epoch 12/20 - Batch 600/1875 - Loss: 0.0007",
    "Epoch 12/20 - Batch 700/1875 - Loss: 0.0348",
    "Epoch 12/20 - Batch 800/1875 - Loss: 0.1406",
    "Epoch 12/20 - Batch 900/1875 - Loss: 0.0100",
    "Epoch 12/20 - Batch 1000/1875 - Loss: 0.1626",
    "Epoch 12/20 - Batch 1100/1875 - Loss: 0.1359",
    "Epoch 12/20 - Batch 1200/1875 - Loss: 0.0782",
    "Epoch 12/20 - Batch 1300/1875 - Loss: 0.0034",
    "Epoch 12/20 - Batch 1400/1875 - Loss: 0.0014",
    "Epoch 12/20 - Batch 1500/1875 - Loss: 0.0752",
    "Epoch 12/20 - Batch 1600/1875 - Loss: 0.0085",
    "Epoch 12/20 - Batch 1700/1875 - Loss: 0.0012",
    "Epoch 12/20 - Batch 1800/1875 - Loss: 0.0029",
    "Epoch 12 completed - Train Acc: 98.75% - Val Acc: 97.96%",
    "Epoch 13/20 - Batch 0/1875 - Loss: 0.0552",
    "Epoch 13/20 - Batch 100/1875 - Loss: 0.0333",
    "Epoch 13/20 - Batch 200/1875 - Loss: 0.0049",
    "Epoch 13/20 - Batch 300/1875 - Loss: 0.0024",
    "Epoch 13/20 - Batch 400/1875 - Loss: 0.0136",
    "Epoch 13/20 - Batch 500/1875 - Loss: 0.1120",
    "Epoch 13/20 - Batch 600/1875 - Loss: 0.0130",
    "Epoch 13/20 - Batch 700/1875 - Loss: 0.0289",
    "Epoch 13/20 - Batch 800/1875 - Loss: 0.0031",
    "Epoch 13/20 - Batch 900/1875 - Loss: 0.0015",
    "Epoch 13/20 - Batch 1000/1875 - Loss: 0.0105",
    "Epoch 13/20 - Batch 1100/1875 - Loss: 0.0034",
    "Epoch 13/20 - Batch 1200/1875 - Loss: 0.1518",
    "Epoch 13/20 - Batch 1300/1875 - Loss: 0.0017",
    "Epoch 13/20 - Batch 1400/1875 - Loss: 0.1655",
    "Epoch 13/20 - Batch 1500/1875 - Loss: 0.0782",
    "Epoch 13/20 - Batch 1600/1875 - Loss: 0.0206",
    "Epoch 13/20 - Batch 1700/1875 - Loss: 0.0029",
    "Epoch 13/20 - Batch 1800/1875 - Loss: 0.0476",
    "Epoch 13 completed - Train Acc: 98.80% - Val Acc: 97.68%",
    "Epoch 14/20 - Batch 0/1875 - Loss: 0.0216",
    "Epoch 14/20 - Batch 100/1875 - Loss: 0.0006",
    "Epoch 14/20 - Batch 200/1875 - Loss: 0.0076",
    "Epoch 14/20 - Batch 300/1875 - Loss: 0.0283",
    "Epoch 14/20 - Batch 400/1875 - Loss: 0.0001",
    "Epoch 14/20 - Batch 500/1875 - Loss: 0.0040",
    "Epoch 14/20 - Batch 600/1875 - Loss: 0.1502",
    "Epoch 14/20 - Batch 700/1875 - Loss: 0.0056",
    "Epoch 14/20 - Batch 800/1875 - Loss: 0.0027",
    "Epoch 14/20 - Batch 900/1875 - Loss: 0.0005",
    "Epoch 14/20 - Batch 1000/1875 - Loss: 0.0018",
    "Epoch 14/20 - Batch 1100/1875 - Loss: 0.0444",
    "Epoch 14/20 - Batch 1200/1875 - Loss: 0.0119",
    "Epoch 14/20 - Batch 1300/1875 - Loss: 0.0263",
    "Epoch 14/20 - Batch 1400/1875 - Loss: 0.0036",
    "Epoch 14/20 - Batch 1500/1875 - Loss: 0.0035",
    "Epoch 14/20 - Batch 1600/1875 - Loss: 0.0072",
    "Epoch 14/20 - Batch 1700/1875 - Loss: 0.1854",
    "Epoch 14/20 - Batch 1800/1875 - Loss: 0.0139",
    "Epoch 14 completed - Train Acc: 98.79% - Val Acc: 97.46%",
    "Epoch 15/20 - Batch 0/1875 - Loss: 0.0192",
    "Epoch 15/20 - Batch 100/1875 - Loss: 0.0799",
    "Epoch 15/20 - Batch 200/1875 - Loss: 0.0008",
    "Epoch 15/20 - Batch 300/1875 - Loss: 0.0020",
    "Epoch 15/20 - Batch 400/1875 - Loss: 0.0032",
    "Epoch 15/20 - Batch 500/1875 - Loss: 0.0194",
    "Epoch 15/20 - Batch 600/1875 - Loss: 0.0062",
    "Epoch 15/20 - Batch 700/1875 - Loss: 0.0023",
    "Epoch 15/20 - Batch 800/1875 - Loss: 0.0015",
    "Epoch 15/20 - Batch 900/1875 - Loss: 0.0071",
    "Epoch 15/20 - Batch 1000/1875 - Loss: 0.1697",
    "Epoch 15/20 - Batch 1100/1875 - Loss: 0.0003",
    "Epoch 15/20 - Batch 1200/1875 - Loss: 0.0098",
    "Epoch 15/20 - Batch 1300/1875 - Loss: 0.1030",
    "Epoch 15/20 - Batch 1400/1875 - Loss: 0.0338",
    "Epoch 15/20 - Batch 1500/1875 - Loss: 0.0008",
    "Epoch 15/20 - Batch 1600/1875 - Loss: 0.0006",
    "Epoch 15/20 - Batch 1700/1875 - Loss: 0.0241",
    "Epoch 15/20 - Batch 1800/1875 - Loss: 0.1635",
    "Epoch 15 completed - Train Acc: 98.86% - Val Acc: 97.44%",
    "Epoch 16/20 - Batch 0/1875 - Loss: 0.0141",
    "Epoch 16/20 - Batch 100/1875 - Loss: 0.0003",
    "Epoch 16/20 - Batch 200/1875 - Loss: 0.0104",
    "Epoch 16/20 - Batch 300/1875 - Loss: 0.0362",
    "Epoch 16/20 - Batch 400/1875 - Loss: 0.0366",
    "Epoch 16/20 - Batch 500/1875 - Loss: 0.0008",
    "Epoch 16/20 - Batch 600/1875 - Loss: 0.0014",
    "Epoch 16/20 - Batch 700/1875 - Loss: 0.0062",
    "Epoch 16/20 - Batch 800/1875 - Loss: 0.0978",
    "Epoch 16/20 - Batch 900/1875 - Loss: 0.0077",
    "Epoch 16/20 - Batch 1000/1875 - Loss: 0.0002",
    "Epoch 16/20 - Batch 1100/1875 - Loss: 0.0027",
    "Epoch 16/20 - Batch 1200/1875 - Loss: 0.1313",
    "Epoch 16/20 - Batch 1300/1875 - Loss: 0.0036",
    "Epoch 16/20 - Batch 1400/1875 - Loss: 0.0008",
    "Epoch 16/20 - Batch 1500/1875 - Loss: 0.0056",
    "Epoch 16/20 - Batch 1600/1875 - Loss: 0.0428",
    "Epoch 16/20 - Batch 1700/1875 - Loss: 0.0011",
    "Epoch 16/20 - Batch 1800/1875 - Loss: 0.0021",
    "Epoch 16 completed - Train Acc: 98.91% - Val Acc: 97.80%",
    "Epoch 17/20 - Batch 0/1875 - Loss: 0.0236",
    "Epoch 17/20 - Batch 100/1875 - Loss: 0.0003",
    "Epoch 17/20 - Batch 200/1875 - Loss: 0.0443",
    "Epoch 17/20 - Batch 300/1875 - Loss: 0.0029",
    "Epoch 17/20 - Batch 400/1875 - Loss: 0.0022",
    "Epoch 17/20 - Batch 500/1875 - Loss: 0.0455",
    "Epoch 17/20 - Batch 600/1875 - Loss: 0.0013",
    "Epoch 17/20 - Batch 700/1875 - Loss: 0.0255",
    "Epoch 17/20 - Batch 800/1875 - Loss: 0.0191",
    "Epoch 17/20 - Batch 900/1875 - Loss: 0.0217",
    "Epoch 17/20 - Batch 1000/1875 - Loss: 0.0471",
    "Epoch 17/20 - Batch 1100/1875 - Loss: 0.0004",
    "Epoch 17/20 - Batch 1200/1875 - Loss: 0.0024",
    "Epoch 17/20 - Batch 1300/1875 - Loss: 0.1245",
    "Epoch 17/20 - Batch 1400/1875 - Loss: 0.1086",
    "Epoch 17/20 - Batch 1500/1875 - Loss: 0.0015",
    "Epoch 17/20 - Batch 1600/1875 - Loss: 0.1251",
    "Epoch 17/20 - Batch 1700/1875 - Loss: 0.0900",
    "Epoch 17/20 - Batch 1800/1875 - Loss: 0.0056",
    "Epoch 17 completed - Train Acc: 98.86% - Val Acc: 97.56%",
    "Epoch 18/20 - Batch 0/1875 - Loss: 0.0038",
    "Epoch 18/20 - Batch 100/1875 - Loss: 0.0236",
    "Epoch 18/20 - Batch 200/1875 - Loss: 0.0903",
    "Epoch 18/20 - Batch 300/1875 - Loss: 0.0034",
    "Epoch 18/20 - Batch 400/1875 - Loss: 0.0083",
    "Epoch 18/20 - Batch 500/1875 - Loss: 0.0455",
    "Epoch 18/20 - Batch 600/1875 - Loss: 0.0034",
    "Epoch 18/20 - Batch 700/1875 - Loss: 0.0023",
    "Epoch 18/20 - Batch 800/1875 - Loss: 0.0281",
    "Epoch 18/20 - Batch 900/1875 - Loss: 0.1534",
    "Epoch 18/20 - Batch 1000/1875 - Loss: 0.1601",
    "Epoch 18/20 - Batch 1100/1875 - Loss: 0.1011",
    "Epoch 18/20 - Batch 1200/1875 - Loss: 0.1124",
    "Epoch 18/20 - Batch 1300/1875 - Loss: 0.0030",
    "Epoch 18/20 - Batch 1400/1875 - Loss: 0.0002",
    "Epoch 18/20 - Batch 1500/1875 - Loss: 0.0073",
    "Epoch 18/20 - Batch 1600/1875 - Loss: 0.2688",
    "Epoch 18/20 - Batch 1700/1875 - Loss: 0.0017",
    "Epoch 18/20 - Batch 1800/1875 - Loss: 0.4037",
    "Epoch 18 completed - Train Acc: 98.92% - Val Acc: 98.06%",
    "Epoch 19/20 - Batch 0/1875 - Loss: 0.0009",
    "Epoch 19/20 - Batch 100/1875 - Loss: 0.0035",
    "Epoch 19/20 - Batch 200/1875 - Loss: 0.0324",
    "Epoch 19/20 - Batch 300/1875 - Loss: 0.1433",
    "Epoch 19/20 - Batch 400/1875 - Loss: 0.0057",
    "Epoch 19/20 - Batch 500/1875 - Loss: 0.0009",
    "Epoch 19/20 - Batch 600/1875 - Loss: 0.1631",
    "Epoch 19/20 - Batch 700/1875 - Loss: 0.0012",
    "Epoch 19/20 - Batch 800/1875 - Loss: 0.0466",
    "Epoch 19/20 - Batch 900/1875 - Loss: 0.1520",
    "Epoch 19/20 - Batch 1000/1875 - Loss: 0.0043",
    "Epoch 19/20 - Batch 1100/1875 - Loss: 0.0708",
    "Epoch 19/20 - Batch 1200/1875 - Loss: 0.0053",
    "Epoch 19/20 - Batch 1300/1875 - Loss: 0.0012",
    "Epoch 19/20 - Batch 1400/1875 - Loss: 0.0097",
    "Epoch 19/20 - Batch 1500/1875 - Loss: 0.0091",
    "Epoch 19/20 - Batch 1600/1875 - Loss: 0.0011",
    "Epoch 19/20 - Batch 1700/1875 - Loss: 0.0075",
    "Epoch 19/20 - Batch 1800/1875 - Loss: 0.0030",
    "Epoch 19 completed - Train Acc: 98.94% - Val Acc: 97.35%",
    "Epoch 20/20 - Batch 0/1875 - Loss: 0.0051",
    "Epoch 20/20 - Batch 100/1875 - Loss: 0.0311",
    "Epoch 20/20 - Batch 200/1875 - Loss: 0.0093",
    "Epoch 20/20 - Batch 300/1875 - Loss: 0.0159",
    "Epoch 20/20 - Batch 400/1875 - Loss: 0.0112",
    "Epoch 20/20 - Batch 500/1875 - Loss: 0.0209",
    "Epoch 20/20 - Batch 600/1875 - Loss: 0.0028",
    "Epoch 20/20 - Batch 700/1875 - Loss: 0.0020",
    "Epoch 20/20 - Batch 800/1875 - Loss: 0.0002",
    "Epoch 20/20 - Batch 900/1875 - Loss: 0.0027",
    "Epoch 20/20 - Batch 1000/1875 - Loss: 0.0257",
    "Epoch 20/20 - Batch 1100/1875 - Loss: 0.0438",
    "Epoch 20/20 - Batch 1200/1875 - Loss: 0.0187",
    "Epoch 20/20 - Batch 1300/1875 - Loss: 0.1002",
    "Epoch 20/20 - Batch 1400/1875 - Loss: 0.1279",
    "Epoch 20/20 - Batch 1500/1875 - Loss: 0.0203",
    "Epoch 20/20 - Batch 1600/1875 - Loss: 0.0007",
    "Epoch 20/20 - Batch 1700/1875 - Loss: 0.0188",
    "Epoch 20/20 - Batch 1800/1875 - Loss: 0.0796",
    "Epoch 20 completed - Train Acc: 98.99% - Val Acc: 97.67%",
    "Training completed. Model saved to models/ZPE-QuantumWeaver-V1.pt"
  ],
  "metrics": [
    {
      "epoch": 1,
      "train_loss": 0.2767914488343522,
      "train_accuracy": 91.59833333333333,
      "val_loss": 0.13612524897548944,
      "val_accuracy": 95.93
    },
    {
      "epoch": 2,
      "train_loss": 0.1307133636948963,
      "train_accuracy": 96.38666666666667,
      "val_loss": 0.12625881582952309,
      "val_accuracy": 96.42
    },
    {
      "epoch": 3,
      "train_loss": 0.1004084197351088,
      "train_accuracy": 97.16833333333334,
      "val_loss": 0.0873985986384704,
      "val_accuracy": 97.69
    },
    {
      "epoch": 4,
      "train_loss": 0.08389964785906487,
      "train_accuracy": 97.64333333333333,
      "val_loss": 0.08980620291163831,
      "val_accuracy": 97.49
    },
    {
      "epoch": 5,
      "train_loss": 0.07251582175169606,
      "train_accuracy": 97.98666666666666,
      "val_loss": 0.09323592706882243,
      "val_accuracy": 97.59
    },
    {
      "epoch": 6,
      "train_loss": 0.06446850322857112,
      "train_accuracy": 98.185,
      "val_loss": 0.12201936856954693,
      "val_accuracy": 97.05
    },
    {
      "epoch": 7,
      "train_loss": 0.0632045764536364,
      "train_accuracy": 98.15666666666667,
      "val_loss": 0.08750200335681364,
      "val_accuracy": 97.68
    },
    {
      "epoch": 8,
      "train_loss": 0.053957391128723976,
      "train_accuracy": 98.43333333333334,
      "val_loss": 0.10356450286233597,
      "val_accuracy": 97.46
    },
    {
      "epoch": 9,
      "train_loss": 0.050015343270346055,
      "train_accuracy": 98.53666666666666,
      "val_loss": 0.08612659553126521,
      "val_accuracy": 97.79
    },
    {
      "epoch": 10,
      "train_loss": 0.04910442301259997,
      "train_accuracy": 98.56666666666666,
      "val_loss": 0.09376190135535058,
      "val_accuracy": 97.41
    },
    {
      "epoch": 11,
      "train_loss": 0.04368722748586442,
      "train_accuracy": 98.66333333333333,
      "val_loss": 0.08830622323487808,
      "val_accuracy": 97.67
    },
    {
      "epoch": 12,
      "train_loss": 0.04322902456620044,
      "train_accuracy": 98.74666666666667,
      "val_loss": 0.0726472179351763,
      "val_accuracy": 97.96
    },
    {
      "epoch": 13,
      "train_loss": 0.04293817436492342,
      "train_accuracy": 98.80333333333333,
      "val_loss": 0.09056252607186212,
      "val_accuracy": 97.68
    },
    {
      "epoch": 14,
      "train_loss": 0.04114766951444132,
      "train_accuracy": 98.79,
      "val_loss": 0.09189140249576196,
      "val_accuracy": 97.46
    },
    {
      "epoch": 15,
      "train_loss": 0.03838946733446016,
      "train_accuracy": 98.865,
      "val_loss": 0.11883602472958031,
      "val_accuracy": 97.44
    },
    {
      "epoch": 16,
      "train_loss": 0.03786612165611247,
      "train_accuracy": 98.90666666666667,
      "val_loss": 0.08990155972117699,
      "val_accuracy": 97.8
    },
    {
      "epoch": 17,
      "train_loss": 0.03991587707105597,
      "train_accuracy": 98.85666666666667,
      "val_loss": 0.1014973273980441,
      "val_accuracy": 97.56
    },
    {
      "epoch": 18,
      "train_loss": 0.03613293852765589,
      "train_accuracy": 98.91833333333334,
      "val_loss": 0.0862117987667552,
      "val_accuracy": 98.06
    },
    {
      "epoch": 19,
      "train_loss": 0.03640069738600675,
      "train_accuracy": 98.93666666666667,
      "val_loss": 0.10626493119862032,
      "val_accuracy": 97.35
    },
    {
      "epoch": 20,
      "train_loss": 0.03420616246369512,
      "train_accuracy": 98.99,
      "val_loss": 0.09947096375992968,
      "val_accuracy": 97.67
    }
  ]
}