{
  "job_id": "zpe_job_30e414c9",
  "status": "completed",
  "parameters": {
    "modelName": "ZPE-QuantumWeaver-V1",
    "totalEpochs": 20,
    "batchSize": 32,
    "learningRate": 0.0011,
    "weightDecay": 0.0001,
    "momentumParams": [
      0.91,
      0.91,
      0.91,
      0.91,
      0.91,
      0.91
    ],
    "strengthParams": [
      0.09,
      0.09,
      0.09,
      0.09,
      0.09,
      0.09
    ],
    "noiseParams": [
      0.011,
      0.011,
      0.011,
      0.011,
      0.011,
      0.011
    ],
    "couplingParams": [
      0.11,
      0.11,
      0.11,
      0.11,
      0.11,
      0.08
    ],
    "quantumCircuitSize": 32,
    "labelSmoothing": 0.1,
    "quantumMode": true,
    "baseConfigId": "zpe_job_d243fa84",
    "mixupAlpha": 0.2
  },
  "start_time": "2025-06-20T05:05:17.496Z",
  "log_messages": [
    "Using device: cuda",
    "Datasets loaded successfully",
    "Model initialized",
    "Epoch 1/20 - Batch 0/1875 - Loss: 2.3012",
    "Epoch 1/20 - Batch 100/1875 - Loss: 0.8042",
    "Epoch 1/20 - Batch 200/1875 - Loss: 0.4174",
    "Epoch 1/20 - Batch 300/1875 - Loss: 0.1703",
    "Epoch 1/20 - Batch 400/1875 - Loss: 0.2596",
    "Epoch 1/20 - Batch 500/1875 - Loss: 0.3259",
    "Epoch 1/20 - Batch 600/1875 - Loss: 0.2500",
    "Epoch 1/20 - Batch 700/1875 - Loss: 0.2419",
    "Epoch 1/20 - Batch 800/1875 - Loss: 0.1513",
    "Epoch 1/20 - Batch 900/1875 - Loss: 0.3731",
    "Epoch 1/20 - Batch 1000/1875 - Loss: 0.3090",
    "Epoch 1/20 - Batch 1100/1875 - Loss: 0.3427",
    "Epoch 1/20 - Batch 1200/1875 - Loss: 0.2075",
    "Epoch 1/20 - Batch 1300/1875 - Loss: 0.0276",
    "Epoch 1/20 - Batch 1400/1875 - Loss: 0.0833",
    "Epoch 1/20 - Batch 1500/1875 - Loss: 0.1119",
    "Epoch 1/20 - Batch 1600/1875 - Loss: 0.1221",
    "Epoch 1/20 - Batch 1700/1875 - Loss: 0.1346",
    "Epoch 1/20 - Batch 1800/1875 - Loss: 0.3139",
    "Epoch 1 completed - Train Acc: 91.78% - Val Acc: 95.98%",
    "Epoch 2/20 - Batch 0/1875 - Loss: 0.2109",
    "Epoch 2/20 - Batch 100/1875 - Loss: 0.0363",
    "Epoch 2/20 - Batch 200/1875 - Loss: 0.2711",
    "Epoch 2/20 - Batch 300/1875 - Loss: 0.0266",
    "Epoch 2/20 - Batch 400/1875 - Loss: 0.1521",
    "Epoch 2/20 - Batch 500/1875 - Loss: 0.1305",
    "Epoch 2/20 - Batch 600/1875 - Loss: 0.0576",
    "Epoch 2/20 - Batch 700/1875 - Loss: 0.0944",
    "Epoch 2/20 - Batch 800/1875 - Loss: 0.2961",
    "Epoch 2/20 - Batch 900/1875 - Loss: 0.1287",
    "Epoch 2/20 - Batch 1000/1875 - Loss: 0.0581",
    "Epoch 2/20 - Batch 1100/1875 - Loss: 0.0639",
    "Epoch 2/20 - Batch 1200/1875 - Loss: 0.0647",
    "Epoch 2/20 - Batch 1300/1875 - Loss: 0.0614",
    "Epoch 2/20 - Batch 1400/1875 - Loss: 0.0522",
    "Epoch 2/20 - Batch 1500/1875 - Loss: 0.0860",
    "Epoch 2/20 - Batch 1600/1875 - Loss: 0.0448",
    "Epoch 2/20 - Batch 1700/1875 - Loss: 0.1285",
    "Epoch 2/20 - Batch 1800/1875 - Loss: 0.0075",
    "Epoch 2 completed - Train Acc: 96.33% - Val Acc: 96.98%",
    "Epoch 3/20 - Batch 0/1875 - Loss: 0.1078",
    "Epoch 3/20 - Batch 100/1875 - Loss: 0.2373",
    "Epoch 3/20 - Batch 200/1875 - Loss: 0.0672",
    "Epoch 3/20 - Batch 300/1875 - Loss: 0.1960",
    "Epoch 3/20 - Batch 400/1875 - Loss: 0.5056",
    "Epoch 3/20 - Batch 500/1875 - Loss: 0.0601",
    "Epoch 3/20 - Batch 600/1875 - Loss: 0.0397",
    "Epoch 3/20 - Batch 700/1875 - Loss: 0.0588",
    "Epoch 3/20 - Batch 800/1875 - Loss: 0.2373",
    "Epoch 3/20 - Batch 900/1875 - Loss: 0.0190",
    "Epoch 3/20 - Batch 1000/1875 - Loss: 0.2039",
    "Epoch 3/20 - Batch 1100/1875 - Loss: 0.1324",
    "Epoch 3/20 - Batch 1200/1875 - Loss: 0.4569",
    "Epoch 3/20 - Batch 1300/1875 - Loss: 0.1558",
    "Epoch 3/20 - Batch 1400/1875 - Loss: 0.1282",
    "Epoch 3/20 - Batch 1500/1875 - Loss: 0.0812",
    "Epoch 3/20 - Batch 1600/1875 - Loss: 0.1219",
    "Epoch 3/20 - Batch 1700/1875 - Loss: 0.0439",
    "Epoch 3/20 - Batch 1800/1875 - Loss: 0.0264",
    "Epoch 3 completed - Train Acc: 97.15% - Val Acc: 97.29%",
    "Epoch 4/20 - Batch 0/1875 - Loss: 0.0644",
    "Epoch 4/20 - Batch 100/1875 - Loss: 0.0300",
    "Epoch 4/20 - Batch 200/1875 - Loss: 0.0124",
    "Epoch 4/20 - Batch 300/1875 - Loss: 0.1446",
    "Epoch 4/20 - Batch 400/1875 - Loss: 0.0010",
    "Epoch 4/20 - Batch 500/1875 - Loss: 0.0891",
    "Epoch 4/20 - Batch 600/1875 - Loss: 0.0228",
    "Epoch 4/20 - Batch 700/1875 - Loss: 0.0825",
    "Epoch 4/20 - Batch 800/1875 - Loss: 0.0236",
    "Epoch 4/20 - Batch 900/1875 - Loss: 0.0037",
    "Epoch 4/20 - Batch 1000/1875 - Loss: 0.1119",
    "Epoch 4/20 - Batch 1100/1875 - Loss: 0.0110",
    "Epoch 4/20 - Batch 1200/1875 - Loss: 0.1106",
    "Epoch 4/20 - Batch 1300/1875 - Loss: 0.1793",
    "Epoch 4/20 - Batch 1400/1875 - Loss: 0.0135",
    "Epoch 4/20 - Batch 1500/1875 - Loss: 0.0090",
    "Epoch 4/20 - Batch 1600/1875 - Loss: 0.1135",
    "Epoch 4/20 - Batch 1700/1875 - Loss: 0.0323",
    "Epoch 4/20 - Batch 1800/1875 - Loss: 0.0333",
    "Epoch 4 completed - Train Acc: 97.58% - Val Acc: 97.44%",
    "Epoch 5/20 - Batch 0/1875 - Loss: 0.0029",
    "Epoch 5/20 - Batch 100/1875 - Loss: 0.0043",
    "Epoch 5/20 - Batch 200/1875 - Loss: 0.1202",
    "Epoch 5/20 - Batch 300/1875 - Loss: 0.2434",
    "Epoch 5/20 - Batch 400/1875 - Loss: 0.0510",
    "Epoch 5/20 - Batch 500/1875 - Loss: 0.1010",
    "Epoch 5/20 - Batch 600/1875 - Loss: 0.0194",
    "Epoch 5/20 - Batch 700/1875 - Loss: 0.1993",
    "Epoch 5/20 - Batch 800/1875 - Loss: 0.0585",
    "Epoch 5/20 - Batch 900/1875 - Loss: 0.1606",
    "Epoch 5/20 - Batch 1000/1875 - Loss: 0.2973",
    "Epoch 5/20 - Batch 1100/1875 - Loss: 0.0571",
    "Epoch 5/20 - Batch 1200/1875 - Loss: 0.0137",
    "Epoch 5/20 - Batch 1300/1875 - Loss: 0.0086",
    "Epoch 5/20 - Batch 1400/1875 - Loss: 0.0468",
    "Epoch 5/20 - Batch 1500/1875 - Loss: 0.1297",
    "Epoch 5/20 - Batch 1600/1875 - Loss: 0.0667",
    "Epoch 5/20 - Batch 1700/1875 - Loss: 0.0333",
    "Epoch 5/20 - Batch 1800/1875 - Loss: 0.0129",
    "Epoch 5 completed - Train Acc: 97.94% - Val Acc: 97.06%",
    "Epoch 6/20 - Batch 0/1875 - Loss: 0.1561",
    "Epoch 6/20 - Batch 100/1875 - Loss: 0.0003",
    "Epoch 6/20 - Batch 200/1875 - Loss: 0.0589",
    "Epoch 6/20 - Batch 300/1875 - Loss: 0.0009",
    "Epoch 6/20 - Batch 400/1875 - Loss: 0.0555",
    "Epoch 6/20 - Batch 500/1875 - Loss: 0.0680",
    "Epoch 6/20 - Batch 600/1875 - Loss: 0.0339",
    "Epoch 6/20 - Batch 700/1875 - Loss: 0.0044",
    "Epoch 6/20 - Batch 800/1875 - Loss: 0.0337",
    "Epoch 6/20 - Batch 900/1875 - Loss: 0.1320",
    "Epoch 6/20 - Batch 1000/1875 - Loss: 0.1928",
    "Epoch 6/20 - Batch 1100/1875 - Loss: 0.0034",
    "Epoch 6/20 - Batch 1200/1875 - Loss: 0.0811",
    "Epoch 6/20 - Batch 1300/1875 - Loss: 0.2053",
    "Epoch 6/20 - Batch 1400/1875 - Loss: 0.0110",
    "Epoch 6/20 - Batch 1500/1875 - Loss: 0.2561",
    "Epoch 6/20 - Batch 1600/1875 - Loss: 0.0075",
    "Epoch 6/20 - Batch 1700/1875 - Loss: 0.0852",
    "Epoch 6/20 - Batch 1800/1875 - Loss: 0.0339",
    "Epoch 6 completed - Train Acc: 98.07% - Val Acc: 97.69%",
    "Epoch 7/20 - Batch 0/1875 - Loss: 0.0035",
    "Epoch 7/20 - Batch 100/1875 - Loss: 0.0051",
    "Epoch 7/20 - Batch 200/1875 - Loss: 0.0034",
    "Epoch 7/20 - Batch 300/1875 - Loss: 0.1362",
    "Epoch 7/20 - Batch 400/1875 - Loss: 0.0121",
    "Epoch 7/20 - Batch 500/1875 - Loss: 0.0170",
    "Epoch 7/20 - Batch 600/1875 - Loss: 0.0668",
    "Epoch 7/20 - Batch 700/1875 - Loss: 0.1843",
    "Epoch 7/20 - Batch 800/1875 - Loss: 0.0014",
    "Epoch 7/20 - Batch 900/1875 - Loss: 0.0191",
    "Epoch 7/20 - Batch 1000/1875 - Loss: 0.1198",
    "Epoch 7/20 - Batch 1100/1875 - Loss: 0.0038",
    "Epoch 7/20 - Batch 1200/1875 - Loss: 0.0400",
    "Epoch 7/20 - Batch 1300/1875 - Loss: 0.0054",
    "Epoch 7/20 - Batch 1400/1875 - Loss: 0.2549",
    "Epoch 7/20 - Batch 1500/1875 - Loss: 0.2963",
    "Epoch 7/20 - Batch 1600/1875 - Loss: 0.0536",
    "Epoch 7/20 - Batch 1700/1875 - Loss: 0.0121",
    "Epoch 7/20 - Batch 1800/1875 - Loss: 0.0058",
    "Epoch 7 completed - Train Acc: 98.31% - Val Acc: 97.87%",
    "Epoch 8/20 - Batch 0/1875 - Loss: 0.0173",
    "Epoch 8/20 - Batch 100/1875 - Loss: 0.0020",
    "Epoch 8/20 - Batch 200/1875 - Loss: 0.0051",
    "Epoch 8/20 - Batch 300/1875 - Loss: 0.0013",
    "Epoch 8/20 - Batch 400/1875 - Loss: 0.0035",
    "Epoch 8/20 - Batch 500/1875 - Loss: 0.0005",
    "Epoch 8/20 - Batch 600/1875 - Loss: 0.0614",
    "Epoch 8/20 - Batch 700/1875 - Loss: 0.4314",
    "Epoch 8/20 - Batch 800/1875 - Loss: 0.0380",
    "Epoch 8/20 - Batch 900/1875 - Loss: 0.0043",
    "Epoch 8/20 - Batch 1000/1875 - Loss: 0.0518",
    "Epoch 8/20 - Batch 1100/1875 - Loss: 0.0076",
    "Epoch 8/20 - Batch 1200/1875 - Loss: 0.1453",
    "Epoch 8/20 - Batch 1300/1875 - Loss: 0.0014",
    "Epoch 8/20 - Batch 1400/1875 - Loss: 0.0761",
    "Epoch 8/20 - Batch 1500/1875 - Loss: 0.0080",
    "Epoch 8/20 - Batch 1600/1875 - Loss: 0.0229",
    "Epoch 8/20 - Batch 1700/1875 - Loss: 0.0253",
    "Epoch 8/20 - Batch 1800/1875 - Loss: 0.0661",
    "Epoch 8 completed - Train Acc: 98.37% - Val Acc: 97.52%",
    "Epoch 9/20 - Batch 0/1875 - Loss: 0.0289",
    "Epoch 9/20 - Batch 100/1875 - Loss: 0.0570",
    "Epoch 9/20 - Batch 200/1875 - Loss: 0.0141",
    "Epoch 9/20 - Batch 300/1875 - Loss: 0.0436",
    "Epoch 9/20 - Batch 400/1875 - Loss: 0.3083",
    "Epoch 9/20 - Batch 500/1875 - Loss: 0.0340",
    "Epoch 9/20 - Batch 600/1875 - Loss: 0.0080",
    "Epoch 9/20 - Batch 700/1875 - Loss: 0.0107",
    "Epoch 9/20 - Batch 800/1875 - Loss: 0.1605",
    "Epoch 9/20 - Batch 900/1875 - Loss: 0.0006",
    "Epoch 9/20 - Batch 1000/1875 - Loss: 0.0287",
    "Epoch 9/20 - Batch 1100/1875 - Loss: 0.1808",
    "Epoch 9/20 - Batch 1200/1875 - Loss: 0.0072",
    "Epoch 9/20 - Batch 1300/1875 - Loss: 0.0804",
    "Epoch 9/20 - Batch 1400/1875 - Loss: 0.2448",
    "Epoch 9/20 - Batch 1500/1875 - Loss: 0.0291",
    "Epoch 9/20 - Batch 1600/1875 - Loss: 0.0061",
    "Epoch 9/20 - Batch 1700/1875 - Loss: 0.0512",
    "Epoch 9/20 - Batch 1800/1875 - Loss: 0.0032",
    "Epoch 9 completed - Train Acc: 98.45% - Val Acc: 97.19%",
    "Epoch 10/20 - Batch 0/1875 - Loss: 0.0360",
    "Epoch 10/20 - Batch 100/1875 - Loss: 0.0045",
    "Epoch 10/20 - Batch 200/1875 - Loss: 0.0081",
    "Epoch 10/20 - Batch 300/1875 - Loss: 0.0015",
    "Epoch 10/20 - Batch 400/1875 - Loss: 0.1126",
    "Epoch 10/20 - Batch 500/1875 - Loss: 0.0001",
    "Epoch 10/20 - Batch 600/1875 - Loss: 0.2697",
    "Epoch 10/20 - Batch 700/1875 - Loss: 0.0219",
    "Epoch 10/20 - Batch 800/1875 - Loss: 0.1142",
    "Epoch 10/20 - Batch 900/1875 - Loss: 0.0016",
    "Epoch 10/20 - Batch 1000/1875 - Loss: 0.0153",
    "Epoch 10/20 - Batch 1100/1875 - Loss: 0.1230",
    "Epoch 10/20 - Batch 1200/1875 - Loss: 0.0170",
    "Epoch 10/20 - Batch 1300/1875 - Loss: 0.0569",
    "Epoch 10/20 - Batch 1400/1875 - Loss: 0.0333",
    "Epoch 10/20 - Batch 1500/1875 - Loss: 0.0003",
    "Epoch 10/20 - Batch 1600/1875 - Loss: 0.1597",
    "Epoch 10/20 - Batch 1700/1875 - Loss: 0.0134",
    "Epoch 10/20 - Batch 1800/1875 - Loss: 0.0033",
    "Epoch 10 completed - Train Acc: 98.60% - Val Acc: 97.15%",
    "Epoch 11/20 - Batch 0/1875 - Loss: 0.0239",
    "Epoch 11/20 - Batch 100/1875 - Loss: 0.0010",
    "Epoch 11/20 - Batch 200/1875 - Loss: 0.1195",
    "Epoch 11/20 - Batch 300/1875 - Loss: 0.0123",
    "Epoch 11/20 - Batch 400/1875 - Loss: 0.0025",
    "Epoch 11/20 - Batch 500/1875 - Loss: 0.0003",
    "Epoch 11/20 - Batch 600/1875 - Loss: 0.0986",
    "Epoch 11/20 - Batch 700/1875 - Loss: 0.0245",
    "Epoch 11/20 - Batch 800/1875 - Loss: 0.0021",
    "Epoch 11/20 - Batch 900/1875 - Loss: 0.0320",
    "Epoch 11/20 - Batch 1000/1875 - Loss: 0.0177",
    "Epoch 11/20 - Batch 1100/1875 - Loss: 0.0055",
    "Epoch 11/20 - Batch 1200/1875 - Loss: 0.0038",
    "Epoch 11/20 - Batch 1300/1875 - Loss: 0.5092",
    "Epoch 11/20 - Batch 1400/1875 - Loss: 0.0019",
    "Epoch 11/20 - Batch 1500/1875 - Loss: 0.0091",
    "Epoch 11/20 - Batch 1600/1875 - Loss: 0.0316",
    "Epoch 11/20 - Batch 1700/1875 - Loss: 0.0003",
    "Epoch 11/20 - Batch 1800/1875 - Loss: 0.0413",
    "Epoch 11 completed - Train Acc: 98.66% - Val Acc: 97.69%",
    "Epoch 12/20 - Batch 0/1875 - Loss: 0.0031",
    "Epoch 12/20 - Batch 100/1875 - Loss: 0.0084",
    "Epoch 12/20 - Batch 200/1875 - Loss: 0.0058",
    "Epoch 12/20 - Batch 300/1875 - Loss: 0.0006",
    "Epoch 12/20 - Batch 400/1875 - Loss: 0.0008",
    "Epoch 12/20 - Batch 500/1875 - Loss: 0.0261",
    "Epoch 12/20 - Batch 600/1875 - Loss: 0.0009",
    "Epoch 12/20 - Batch 700/1875 - Loss: 0.0130",
    "Epoch 12/20 - Batch 800/1875 - Loss: 0.0022",
    "Epoch 12/20 - Batch 900/1875 - Loss: 0.0025",
    "Epoch 12/20 - Batch 1000/1875 - Loss: 0.0048",
    "Epoch 12/20 - Batch 1100/1875 - Loss: 0.0046",
    "Epoch 12/20 - Batch 1200/1875 - Loss: 0.0134",
    "Epoch 12/20 - Batch 1300/1875 - Loss: 0.0368",
    "Epoch 12/20 - Batch 1400/1875 - Loss: 0.0169",
    "Epoch 12/20 - Batch 1500/1875 - Loss: 0.0123",
    "Epoch 12/20 - Batch 1600/1875 - Loss: 0.0063",
    "Epoch 12/20 - Batch 1700/1875 - Loss: 0.0053",
    "Epoch 12/20 - Batch 1800/1875 - Loss: 0.0018",
    "Epoch 12 completed - Train Acc: 98.69% - Val Acc: 98.04%",
    "Epoch 13/20 - Batch 0/1875 - Loss: 0.0032",
    "Epoch 13/20 - Batch 100/1875 - Loss: 0.0263",
    "Epoch 13/20 - Batch 200/1875 - Loss: 0.0323",
    "Epoch 13/20 - Batch 300/1875 - Loss: 0.0307",
    "Epoch 13/20 - Batch 400/1875 - Loss: 0.0003",
    "Epoch 13/20 - Batch 500/1875 - Loss: 0.0030",
    "Epoch 13/20 - Batch 600/1875 - Loss: 0.0356",
    "Epoch 13/20 - Batch 700/1875 - Loss: 0.1729",
    "Epoch 13/20 - Batch 800/1875 - Loss: 0.0062",
    "Epoch 13/20 - Batch 900/1875 - Loss: 0.0208",
    "Epoch 13/20 - Batch 1000/1875 - Loss: 0.0012",
    "Epoch 13/20 - Batch 1100/1875 - Loss: 0.1072",
    "Epoch 13/20 - Batch 1200/1875 - Loss: 0.0036",
    "Epoch 13/20 - Batch 1300/1875 - Loss: 0.1410",
    "Epoch 13/20 - Batch 1400/1875 - Loss: 0.0576",
    "Epoch 13/20 - Batch 1500/1875 - Loss: 0.0327",
    "Epoch 13/20 - Batch 1600/1875 - Loss: 0.0401",
    "Epoch 13/20 - Batch 1700/1875 - Loss: 0.0061",
    "Epoch 13/20 - Batch 1800/1875 - Loss: 0.0029",
    "Epoch 13 completed - Train Acc: 98.70% - Val Acc: 97.60%",
    "Epoch 14/20 - Batch 0/1875 - Loss: 0.0272",
    "Epoch 14/20 - Batch 100/1875 - Loss: 0.0116",
    "Epoch 14/20 - Batch 200/1875 - Loss: 0.1385",
    "Epoch 14/20 - Batch 300/1875 - Loss: 0.0139",
    "Epoch 14/20 - Batch 400/1875 - Loss: 0.0030",
    "Epoch 14/20 - Batch 500/1875 - Loss: 0.0281",
    "Epoch 14/20 - Batch 600/1875 - Loss: 0.0214",
    "Epoch 14/20 - Batch 700/1875 - Loss: 0.0033",
    "Epoch 14/20 - Batch 800/1875 - Loss: 0.0712",
    "Epoch 14/20 - Batch 900/1875 - Loss: 0.1674",
    "Epoch 14/20 - Batch 1000/1875 - Loss: 0.0612",
    "Epoch 14/20 - Batch 1100/1875 - Loss: 0.0011",
    "Epoch 14/20 - Batch 1200/1875 - Loss: 0.0078",
    "Epoch 14/20 - Batch 1300/1875 - Loss: 0.0181",
    "Epoch 14/20 - Batch 1400/1875 - Loss: 0.0007",
    "Epoch 14/20 - Batch 1500/1875 - Loss: 0.0075",
    "Epoch 14/20 - Batch 1600/1875 - Loss: 0.0253",
    "Epoch 14/20 - Batch 1700/1875 - Loss: 0.0014",
    "Epoch 14/20 - Batch 1800/1875 - Loss: 0.0006",
    "Epoch 14 completed - Train Acc: 98.78% - Val Acc: 97.65%",
    "Epoch 15/20 - Batch 0/1875 - Loss: 0.0901",
    "Epoch 15/20 - Batch 100/1875 - Loss: 0.0011",
    "Epoch 15/20 - Batch 200/1875 - Loss: 0.0041",
    "Epoch 15/20 - Batch 300/1875 - Loss: 0.0051",
    "Epoch 15/20 - Batch 400/1875 - Loss: 0.0017",
    "Epoch 15/20 - Batch 500/1875 - Loss: 0.0005",
    "Epoch 15/20 - Batch 600/1875 - Loss: 0.0006",
    "Epoch 15/20 - Batch 700/1875 - Loss: 0.0083",
    "Epoch 15/20 - Batch 800/1875 - Loss: 0.1617",
    "Epoch 15/20 - Batch 900/1875 - Loss: 0.2025",
    "Epoch 15/20 - Batch 1000/1875 - Loss: 0.0025",
    "Epoch 15/20 - Batch 1100/1875 - Loss: 0.0003",
    "Epoch 15/20 - Batch 1200/1875 - Loss: 0.0244",
    "Epoch 15/20 - Batch 1300/1875 - Loss: 0.0023",
    "Epoch 15/20 - Batch 1400/1875 - Loss: 0.0020",
    "Epoch 15/20 - Batch 1500/1875 - Loss: 0.0529",
    "Epoch 15/20 - Batch 1600/1875 - Loss: 0.2270",
    "Epoch 15/20 - Batch 1700/1875 - Loss: 0.2677",
    "Epoch 15/20 - Batch 1800/1875 - Loss: 0.0580",
    "Epoch 15 completed - Train Acc: 98.71% - Val Acc: 98.02%",
    "Epoch 16/20 - Batch 0/1875 - Loss: 0.0047",
    "Epoch 16/20 - Batch 100/1875 - Loss: 0.0150",
    "Epoch 16/20 - Batch 200/1875 - Loss: 0.0299",
    "Epoch 16/20 - Batch 300/1875 - Loss: 0.0088",
    "Epoch 16/20 - Batch 400/1875 - Loss: 0.0028",
    "Epoch 16/20 - Batch 500/1875 - Loss: 0.0012",
    "Epoch 16/20 - Batch 600/1875 - Loss: 0.0047",
    "Epoch 16/20 - Batch 700/1875 - Loss: 0.0184",
    "Epoch 16/20 - Batch 800/1875 - Loss: 0.0419",
    "Epoch 16/20 - Batch 900/1875 - Loss: 0.0077",
    "Epoch 16/20 - Batch 1000/1875 - Loss: 0.0014",
    "Epoch 16/20 - Batch 1100/1875 - Loss: 0.0017",
    "Epoch 16/20 - Batch 1200/1875 - Loss: 0.0001",
    "Epoch 16/20 - Batch 1300/1875 - Loss: 0.0018",
    "Epoch 16/20 - Batch 1400/1875 - Loss: 0.2370",
    "Epoch 16/20 - Batch 1500/1875 - Loss: 0.0634",
    "Epoch 16/20 - Batch 1600/1875 - Loss: 0.0089",
    "Epoch 16/20 - Batch 1700/1875 - Loss: 0.0020",
    "Epoch 16/20 - Batch 1800/1875 - Loss: 0.0028",
    "Epoch 16 completed - Train Acc: 98.84% - Val Acc: 97.77%",
    "Epoch 17/20 - Batch 0/1875 - Loss: 0.0008",
    "Epoch 17/20 - Batch 100/1875 - Loss: 0.2508",
    "Epoch 17/20 - Batch 200/1875 - Loss: 0.0016",
    "Epoch 17/20 - Batch 300/1875 - Loss: 0.1456",
    "Epoch 17/20 - Batch 400/1875 - Loss: 0.0150",
    "Epoch 17/20 - Batch 500/1875 - Loss: 0.0424",
    "Epoch 17/20 - Batch 600/1875 - Loss: 0.0002",
    "Epoch 17/20 - Batch 700/1875 - Loss: 0.0468",
    "Epoch 17/20 - Batch 800/1875 - Loss: 0.0124",
    "Epoch 17/20 - Batch 900/1875 - Loss: 0.0137",
    "Epoch 17/20 - Batch 1000/1875 - Loss: 0.0186",
    "Epoch 17/20 - Batch 1100/1875 - Loss: 0.0001",
    "Epoch 17/20 - Batch 1200/1875 - Loss: 0.0241",
    "Epoch 17/20 - Batch 1300/1875 - Loss: 0.0006",
    "Epoch 17/20 - Batch 1400/1875 - Loss: 0.5228",
    "Epoch 17/20 - Batch 1500/1875 - Loss: 0.0229",
    "Epoch 17/20 - Batch 1600/1875 - Loss: 0.0034",
    "Epoch 17/20 - Batch 1700/1875 - Loss: 0.0033",
    "Epoch 17/20 - Batch 1800/1875 - Loss: 0.0099",
    "Epoch 17 completed - Train Acc: 98.94% - Val Acc: 97.75%",
    "Epoch 18/20 - Batch 0/1875 - Loss: 0.0419",
    "Epoch 18/20 - Batch 100/1875 - Loss: 0.1158",
    "Epoch 18/20 - Batch 200/1875 - Loss: 0.0184",
    "Epoch 18/20 - Batch 300/1875 - Loss: 0.0294",
    "Epoch 18/20 - Batch 400/1875 - Loss: 0.0109",
    "Epoch 18/20 - Batch 500/1875 - Loss: 0.0006",
    "Epoch 18/20 - Batch 600/1875 - Loss: 0.0053",
    "Epoch 18/20 - Batch 700/1875 - Loss: 0.0037",
    "Epoch 18/20 - Batch 800/1875 - Loss: 0.0039",
    "Epoch 18/20 - Batch 900/1875 - Loss: 0.0018",
    "Epoch 18/20 - Batch 1000/1875 - Loss: 0.0017",
    "Epoch 18/20 - Batch 1100/1875 - Loss: 0.0123",
    "Epoch 18/20 - Batch 1200/1875 - Loss: 0.0062",
    "Epoch 18/20 - Batch 1300/1875 - Loss: 0.0104",
    "Epoch 18/20 - Batch 1400/1875 - Loss: 0.0014",
    "Epoch 18/20 - Batch 1500/1875 - Loss: 0.0125",
    "Epoch 18/20 - Batch 1600/1875 - Loss: 0.0050",
    "Epoch 18/20 - Batch 1700/1875 - Loss: 0.0024",
    "Epoch 18/20 - Batch 1800/1875 - Loss: 0.0546",
    "Epoch 18 completed - Train Acc: 98.84% - Val Acc: 97.85%",
    "Epoch 19/20 - Batch 0/1875 - Loss: 0.0151",
    "Epoch 19/20 - Batch 100/1875 - Loss: 0.0009",
    "Epoch 19/20 - Batch 200/1875 - Loss: 0.0012",
    "Epoch 19/20 - Batch 300/1875 - Loss: 0.0237",
    "Epoch 19/20 - Batch 400/1875 - Loss: 0.0036",
    "Epoch 19/20 - Batch 500/1875 - Loss: 0.0166",
    "Epoch 19/20 - Batch 600/1875 - Loss: 0.0079",
    "Epoch 19/20 - Batch 700/1875 - Loss: 0.0888",
    "Epoch 19/20 - Batch 800/1875 - Loss: 0.0042",
    "Epoch 19/20 - Batch 900/1875 - Loss: 0.0011",
    "Epoch 19/20 - Batch 1000/1875 - Loss: 0.0165",
    "Epoch 19/20 - Batch 1100/1875 - Loss: 0.0212",
    "Epoch 19/20 - Batch 1200/1875 - Loss: 0.0968",
    "Epoch 19/20 - Batch 1300/1875 - Loss: 0.0013",
    "Epoch 19/20 - Batch 1400/1875 - Loss: 0.1117",
    "Epoch 19/20 - Batch 1500/1875 - Loss: 0.0017",
    "Epoch 19/20 - Batch 1600/1875 - Loss: 0.0035",
    "Epoch 19/20 - Batch 1700/1875 - Loss: 0.1501",
    "Epoch 19/20 - Batch 1800/1875 - Loss: 0.0020",
    "Epoch 19 completed - Train Acc: 98.83% - Val Acc: 97.88%",
    "Epoch 20/20 - Batch 0/1875 - Loss: 0.0563",
    "Epoch 20/20 - Batch 100/1875 - Loss: 0.1034",
    "Epoch 20/20 - Batch 200/1875 - Loss: 0.0224",
    "Epoch 20/20 - Batch 300/1875 - Loss: 0.0554",
    "Epoch 20/20 - Batch 400/1875 - Loss: 0.1533",
    "Epoch 20/20 - Batch 500/1875 - Loss: 0.0015",
    "Epoch 20/20 - Batch 600/1875 - Loss: 0.0113",
    "Epoch 20/20 - Batch 700/1875 - Loss: 0.0484",
    "Epoch 20/20 - Batch 800/1875 - Loss: 0.2768",
    "Epoch 20/20 - Batch 900/1875 - Loss: 0.0002",
    "Epoch 20/20 - Batch 1000/1875 - Loss: 0.0508",
    "Epoch 20/20 - Batch 1100/1875 - Loss: 0.0271",
    "Epoch 20/20 - Batch 1200/1875 - Loss: 0.0014",
    "Epoch 20/20 - Batch 1300/1875 - Loss: 0.0836",
    "Epoch 20/20 - Batch 1400/1875 - Loss: 0.0627",
    "Epoch 20/20 - Batch 1500/1875 - Loss: 0.0171",
    "Epoch 20/20 - Batch 1600/1875 - Loss: 0.0148",
    "Epoch 20/20 - Batch 1700/1875 - Loss: 0.0086",
    "Epoch 20/20 - Batch 1800/1875 - Loss: 0.0033",
    "Epoch 20 completed - Train Acc: 98.96% - Val Acc: 97.93%",
    "Training completed. Model saved to models/ZPE-QuantumWeaver-V1.pt"
  ],
  "metrics": [
    {
      "epoch": 1,
      "train_loss": 0.2712327631237606,
      "train_accuracy": 91.78,
      "val_loss": 0.13343141255488347,
      "val_accuracy": 95.98
    },
    {
      "epoch": 2,
      "train_loss": 0.13475767364079755,
      "train_accuracy": 96.325,
      "val_loss": 0.10505150579008685,
      "val_accuracy": 96.98
    },
    {
      "epoch": 3,
      "train_loss": 0.1019979917045993,
      "train_accuracy": 97.14833333333333,
      "val_loss": 0.10005308663697181,
      "val_accuracy": 97.29
    },
    {
      "epoch": 4,
      "train_loss": 0.08698513336355487,
      "train_accuracy": 97.57833333333333,
      "val_loss": 0.08853476135634457,
      "val_accuracy": 97.44
    },
    {
      "epoch": 5,
      "train_loss": 0.07574529366385346,
      "train_accuracy": 97.945,
      "val_loss": 0.11323429120517821,
      "val_accuracy": 97.06
    },
    {
      "epoch": 6,
      "train_loss": 0.06882310155860615,
      "train_accuracy": 98.07,
      "val_loss": 0.08175553759523167,
      "val_accuracy": 97.69
    },
    {
      "epoch": 7,
      "train_loss": 0.05839535097880677,
      "train_accuracy": 98.31333333333333,
      "val_loss": 0.08303387126666936,
      "val_accuracy": 97.87
    },
    {
      "epoch": 8,
      "train_loss": 0.05709113221434721,
      "train_accuracy": 98.36833333333334,
      "val_loss": 0.08515023492547855,
      "val_accuracy": 97.52
    },
    {
      "epoch": 9,
      "train_loss": 0.05390045926710979,
      "train_accuracy": 98.455,
      "val_loss": 0.10563286232268575,
      "val_accuracy": 97.19
    },
    {
      "epoch": 10,
      "train_loss": 0.04925168701525739,
      "train_accuracy": 98.59833333333333,
      "val_loss": 0.1062804310189351,
      "val_accuracy": 97.15
    },
    {
      "epoch": 11,
      "train_loss": 0.045747262861366225,
      "train_accuracy": 98.65833333333333,
      "val_loss": 0.09368061252899235,
      "val_accuracy": 97.69
    },
    {
      "epoch": 12,
      "train_loss": 0.0463750182089357,
      "train_accuracy": 98.69,
      "val_loss": 0.07435066998303623,
      "val_accuracy": 98.04
    },
    {
      "epoch": 13,
      "train_loss": 0.04483512481526025,
      "train_accuracy": 98.70333333333333,
      "val_loss": 0.09712898014277888,
      "val_accuracy": 97.6
    },
    {
      "epoch": 14,
      "train_loss": 0.04151151727795174,
      "train_accuracy": 98.775,
      "val_loss": 0.08970353873174723,
      "val_accuracy": 97.65
    },
    {
      "epoch": 15,
      "train_loss": 0.0433669670260589,
      "train_accuracy": 98.71,
      "val_loss": 0.08883155299854217,
      "val_accuracy": 98.02
    },
    {
      "epoch": 16,
      "train_loss": 0.039498740677479265,
      "train_accuracy": 98.83833333333334,
      "val_loss": 0.08686490237600512,
      "val_accuracy": 97.77
    },
    {
      "epoch": 17,
      "train_loss": 0.03720985364779384,
      "train_accuracy": 98.93833333333333,
      "val_loss": 0.10896506441700715,
      "val_accuracy": 97.75
    },
    {
      "epoch": 18,
      "train_loss": 0.039827594997518465,
      "train_accuracy": 98.84333333333333,
      "val_loss": 0.08127490372136524,
      "val_accuracy": 97.85
    },
    {
      "epoch": 19,
      "train_loss": 0.03837607121749315,
      "train_accuracy": 98.82833333333333,
      "val_loss": 0.0818768286920032,
      "val_accuracy": 97.88
    },
    {
      "epoch": 20,
      "train_loss": 0.03474928608774159,
      "train_accuracy": 98.96166666666667,
      "val_loss": 0.09039230792456138,
      "val_accuracy": 97.93
    }
  ]
}