{
  "job_id": "zpe_job_e89f8c65",
  "status": "completed",
  "parameters": {
    "modelName": "ZPE-QuantumWeaver-V1",
    "totalEpochs": 20,
    "batchSize": 32,
    "learningRate": 0.0011,
    "weightDecay": 0.0001,
    "momentumParams": [
      0.91,
      0.91,
      0.91,
      0.91,
      0.91,
      0.91
    ],
    "strengthParams": [
      0.09,
      0.09,
      0.09,
      0.09,
      0.09,
      0.09
    ],
    "noiseParams": [
      0.011,
      0.011,
      0.011,
      0.011,
      0.011,
      0.011
    ],
    "couplingParams": [
      0.11,
      0.11,
      0.11,
      0.11,
      0.11,
      0.08
    ],
    "quantumCircuitSize": 32,
    "labelSmoothing": 0.1,
    "quantumMode": true,
    "baseConfigId": "zpe_job_d243fa84",
    "mixupAlpha": 0.2
  },
  "start_time": "2025-06-20T05:29:29.131Z",
  "log_messages": [
    "Using device: cuda",
    "Datasets loaded successfully",
    "Model initialized",
    "Epoch 1/20 - Batch 0/1875 - Loss: 2.2963",
    "Epoch 1/20 - Batch 100/1875 - Loss: 0.3011",
    "Epoch 1/20 - Batch 200/1875 - Loss: 0.5979",
    "Epoch 1/20 - Batch 300/1875 - Loss: 0.1191",
    "Epoch 1/20 - Batch 400/1875 - Loss: 0.1887",
    "Epoch 1/20 - Batch 500/1875 - Loss: 0.4307",
    "Epoch 1/20 - Batch 600/1875 - Loss: 0.1460",
    "Epoch 1/20 - Batch 700/1875 - Loss: 0.2435",
    "Epoch 1/20 - Batch 800/1875 - Loss: 0.1505",
    "Epoch 1/20 - Batch 900/1875 - Loss: 0.3031",
    "Epoch 1/20 - Batch 1000/1875 - Loss: 0.0875",
    "Epoch 1/20 - Batch 1100/1875 - Loss: 0.2258",
    "Epoch 1/20 - Batch 1200/1875 - Loss: 0.0458",
    "Epoch 1/20 - Batch 1300/1875 - Loss: 0.0317",
    "Epoch 1/20 - Batch 1400/1875 - Loss: 0.1788",
    "Epoch 1/20 - Batch 1500/1875 - Loss: 0.1221",
    "Epoch 1/20 - Batch 1600/1875 - Loss: 0.0128",
    "Epoch 1/20 - Batch 1700/1875 - Loss: 0.1811",
    "Epoch 1/20 - Batch 1800/1875 - Loss: 0.3205",
    "Epoch 1 completed - Train Acc: 91.97% - Val Acc: 95.91%",
    "Epoch 2/20 - Batch 0/1875 - Loss: 0.0549",
    "Epoch 2/20 - Batch 100/1875 - Loss: 0.1863",
    "Epoch 2/20 - Batch 200/1875 - Loss: 0.0319",
    "Epoch 2/20 - Batch 300/1875 - Loss: 0.1972",
    "Epoch 2/20 - Batch 400/1875 - Loss: 0.0744",
    "Epoch 2/20 - Batch 500/1875 - Loss: 0.2596",
    "Epoch 2/20 - Batch 600/1875 - Loss: 0.2244",
    "Epoch 2/20 - Batch 700/1875 - Loss: 0.2814",
    "Epoch 2/20 - Batch 800/1875 - Loss: 0.3003",
    "Epoch 2/20 - Batch 900/1875 - Loss: 0.0648",
    "Epoch 2/20 - Batch 1000/1875 - Loss: 0.0899",
    "Epoch 2/20 - Batch 1100/1875 - Loss: 0.0893",
    "Epoch 2/20 - Batch 1200/1875 - Loss: 0.0740",
    "Epoch 2/20 - Batch 1300/1875 - Loss: 0.1753",
    "Epoch 2/20 - Batch 1400/1875 - Loss: 0.3712",
    "Epoch 2/20 - Batch 1500/1875 - Loss: 0.6889",
    "Epoch 2/20 - Batch 1600/1875 - Loss: 0.0133",
    "Epoch 2/20 - Batch 1700/1875 - Loss: 0.0929",
    "Epoch 2/20 - Batch 1800/1875 - Loss: 0.2933",
    "Epoch 2 completed - Train Acc: 96.36% - Val Acc: 95.51%",
    "Epoch 3/20 - Batch 0/1875 - Loss: 0.1244",
    "Epoch 3/20 - Batch 100/1875 - Loss: 0.0998",
    "Epoch 3/20 - Batch 200/1875 - Loss: 0.0159",
    "Epoch 3/20 - Batch 300/1875 - Loss: 0.0031",
    "Epoch 3/20 - Batch 400/1875 - Loss: 0.0105",
    "Epoch 3/20 - Batch 500/1875 - Loss: 0.2069",
    "Epoch 3/20 - Batch 600/1875 - Loss: 0.0321",
    "Epoch 3/20 - Batch 700/1875 - Loss: 0.0395",
    "Epoch 3/20 - Batch 800/1875 - Loss: 0.0965",
    "Epoch 3/20 - Batch 900/1875 - Loss: 0.0289",
    "Epoch 3/20 - Batch 1000/1875 - Loss: 0.1196",
    "Epoch 3/20 - Batch 1100/1875 - Loss: 0.1614",
    "Epoch 3/20 - Batch 1200/1875 - Loss: 0.2473",
    "Epoch 3/20 - Batch 1300/1875 - Loss: 0.0288",
    "Epoch 3/20 - Batch 1400/1875 - Loss: 0.1379",
    "Epoch 3/20 - Batch 1500/1875 - Loss: 0.0322",
    "Epoch 3/20 - Batch 1600/1875 - Loss: 0.0138",
    "Epoch 3/20 - Batch 1700/1875 - Loss: 0.2488",
    "Epoch 3/20 - Batch 1800/1875 - Loss: 0.0639",
    "Epoch 3 completed - Train Acc: 97.22% - Val Acc: 96.82%",
    "Epoch 4/20 - Batch 0/1875 - Loss: 0.0062",
    "Epoch 4/20 - Batch 100/1875 - Loss: 0.0193",
    "Epoch 4/20 - Batch 200/1875 - Loss: 0.0480",
    "Epoch 4/20 - Batch 300/1875 - Loss: 0.1335",
    "Epoch 4/20 - Batch 400/1875 - Loss: 0.2173",
    "Epoch 4/20 - Batch 500/1875 - Loss: 0.3383",
    "Epoch 4/20 - Batch 600/1875 - Loss: 0.0432",
    "Epoch 4/20 - Batch 700/1875 - Loss: 0.2988",
    "Epoch 4/20 - Batch 800/1875 - Loss: 0.0235",
    "Epoch 4/20 - Batch 900/1875 - Loss: 0.0862",
    "Epoch 4/20 - Batch 1000/1875 - Loss: 0.2773",
    "Epoch 4/20 - Batch 1100/1875 - Loss: 0.1581",
    "Epoch 4/20 - Batch 1200/1875 - Loss: 0.0284",
    "Epoch 4/20 - Batch 1300/1875 - Loss: 0.0399",
    "Epoch 4/20 - Batch 1400/1875 - Loss: 0.0028",
    "Epoch 4/20 - Batch 1500/1875 - Loss: 0.0255",
    "Epoch 4/20 - Batch 1600/1875 - Loss: 0.0006",
    "Epoch 4/20 - Batch 1700/1875 - Loss: 0.0773",
    "Epoch 4/20 - Batch 1800/1875 - Loss: 0.3275",
    "Epoch 4 completed - Train Acc: 97.57% - Val Acc: 97.48%",
    "Epoch 5/20 - Batch 0/1875 - Loss: 0.0064",
    "Epoch 5/20 - Batch 100/1875 - Loss: 0.0076",
    "Epoch 5/20 - Batch 200/1875 - Loss: 0.0110",
    "Epoch 5/20 - Batch 300/1875 - Loss: 0.0161",
    "Epoch 5/20 - Batch 400/1875 - Loss: 0.0018",
    "Epoch 5/20 - Batch 500/1875 - Loss: 0.0047",
    "Epoch 5/20 - Batch 600/1875 - Loss: 0.1066",
    "Epoch 5/20 - Batch 700/1875 - Loss: 0.0700",
    "Epoch 5/20 - Batch 800/1875 - Loss: 0.0704",
    "Epoch 5/20 - Batch 900/1875 - Loss: 0.0494",
    "Epoch 5/20 - Batch 1000/1875 - Loss: 0.1159",
    "Epoch 5/20 - Batch 1100/1875 - Loss: 0.0221",
    "Epoch 5/20 - Batch 1200/1875 - Loss: 0.0070",
    "Epoch 5/20 - Batch 1300/1875 - Loss: 0.2912",
    "Epoch 5/20 - Batch 1400/1875 - Loss: 0.0953",
    "Epoch 5/20 - Batch 1500/1875 - Loss: 0.1173",
    "Epoch 5/20 - Batch 1600/1875 - Loss: 0.2221",
    "Epoch 5/20 - Batch 1700/1875 - Loss: 0.0053",
    "Epoch 5/20 - Batch 1800/1875 - Loss: 0.2254",
    "Epoch 5 completed - Train Acc: 97.94% - Val Acc: 96.81%",
    "Epoch 6/20 - Batch 0/1875 - Loss: 0.0081",
    "Epoch 6/20 - Batch 100/1875 - Loss: 0.0313",
    "Epoch 6/20 - Batch 200/1875 - Loss: 0.0797",
    "Epoch 6/20 - Batch 300/1875 - Loss: 0.0246",
    "Epoch 6/20 - Batch 400/1875 - Loss: 0.0678",
    "Epoch 6/20 - Batch 500/1875 - Loss: 0.0012",
    "Epoch 6/20 - Batch 600/1875 - Loss: 0.1214",
    "Epoch 6/20 - Batch 700/1875 - Loss: 0.0840",
    "Epoch 6/20 - Batch 800/1875 - Loss: 0.0076",
    "Epoch 6/20 - Batch 900/1875 - Loss: 0.0188",
    "Epoch 6/20 - Batch 1000/1875 - Loss: 0.2686",
    "Epoch 6/20 - Batch 1100/1875 - Loss: 0.2833",
    "Epoch 6/20 - Batch 1200/1875 - Loss: 0.0520",
    "Epoch 6/20 - Batch 1300/1875 - Loss: 0.0266",
    "Epoch 6/20 - Batch 1400/1875 - Loss: 0.0653",
    "Epoch 6/20 - Batch 1500/1875 - Loss: 0.0019",
    "Epoch 6/20 - Batch 1600/1875 - Loss: 0.0346",
    "Epoch 6/20 - Batch 1700/1875 - Loss: 0.0322",
    "Epoch 6/20 - Batch 1800/1875 - Loss: 0.0210",
    "Epoch 6 completed - Train Acc: 98.16% - Val Acc: 97.61%",
    "Epoch 7/20 - Batch 0/1875 - Loss: 0.0049",
    "Epoch 7/20 - Batch 100/1875 - Loss: 0.2856",
    "Epoch 7/20 - Batch 200/1875 - Loss: 0.0406",
    "Epoch 7/20 - Batch 300/1875 - Loss: 0.0647",
    "Epoch 7/20 - Batch 400/1875 - Loss: 0.0041",
    "Epoch 7/20 - Batch 500/1875 - Loss: 0.0800",
    "Epoch 7/20 - Batch 600/1875 - Loss: 0.2127",
    "Epoch 7/20 - Batch 700/1875 - Loss: 0.0476",
    "Epoch 7/20 - Batch 800/1875 - Loss: 0.0276",
    "Epoch 7/20 - Batch 900/1875 - Loss: 0.0158",
    "Epoch 7/20 - Batch 1000/1875 - Loss: 0.1086",
    "Epoch 7/20 - Batch 1100/1875 - Loss: 0.0055",
    "Epoch 7/20 - Batch 1200/1875 - Loss: 0.0153",
    "Epoch 7/20 - Batch 1300/1875 - Loss: 0.0116",
    "Epoch 7/20 - Batch 1400/1875 - Loss: 0.0261",
    "Epoch 7/20 - Batch 1500/1875 - Loss: 0.0158",
    "Epoch 7/20 - Batch 1600/1875 - Loss: 0.0200",
    "Epoch 7/20 - Batch 1700/1875 - Loss: 0.0232",
    "Epoch 7/20 - Batch 1800/1875 - Loss: 0.1100",
    "Epoch 7 completed - Train Acc: 98.29% - Val Acc: 97.38%",
    "Epoch 8/20 - Batch 0/1875 - Loss: 0.0022",
    "Epoch 8/20 - Batch 100/1875 - Loss: 0.1626",
    "Epoch 8/20 - Batch 200/1875 - Loss: 0.0798",
    "Epoch 8/20 - Batch 300/1875 - Loss: 0.0020",
    "Epoch 8/20 - Batch 400/1875 - Loss: 0.1237",
    "Epoch 8/20 - Batch 500/1875 - Loss: 0.0131",
    "Epoch 8/20 - Batch 600/1875 - Loss: 0.0108",
    "Epoch 8/20 - Batch 700/1875 - Loss: 0.0914",
    "Epoch 8/20 - Batch 800/1875 - Loss: 0.0582",
    "Epoch 8/20 - Batch 900/1875 - Loss: 0.0147",
    "Epoch 8/20 - Batch 1000/1875 - Loss: 0.0261",
    "Epoch 8/20 - Batch 1100/1875 - Loss: 0.0191",
    "Epoch 8/20 - Batch 1200/1875 - Loss: 0.0223",
    "Epoch 8/20 - Batch 1300/1875 - Loss: 0.0100",
    "Epoch 8/20 - Batch 1400/1875 - Loss: 0.0138",
    "Epoch 8/20 - Batch 1500/1875 - Loss: 0.0218",
    "Epoch 8/20 - Batch 1600/1875 - Loss: 0.0609",
    "Epoch 8/20 - Batch 1700/1875 - Loss: 0.1141",
    "Epoch 8/20 - Batch 1800/1875 - Loss: 0.0908",
    "Epoch 8 completed - Train Acc: 98.36% - Val Acc: 97.22%",
    "Epoch 9/20 - Batch 0/1875 - Loss: 0.0055",
    "Epoch 9/20 - Batch 100/1875 - Loss: 0.0543",
    "Epoch 9/20 - Batch 200/1875 - Loss: 0.0094",
    "Epoch 9/20 - Batch 300/1875 - Loss: 0.0004",
    "Epoch 9/20 - Batch 400/1875 - Loss: 0.0018",
    "Epoch 9/20 - Batch 500/1875 - Loss: 0.0095",
    "Epoch 9/20 - Batch 600/1875 - Loss: 0.1296",
    "Epoch 9/20 - Batch 700/1875 - Loss: 0.0017",
    "Epoch 9/20 - Batch 800/1875 - Loss: 0.0120",
    "Epoch 9/20 - Batch 900/1875 - Loss: 0.0034",
    "Epoch 9/20 - Batch 1000/1875 - Loss: 0.0890",
    "Epoch 9/20 - Batch 1100/1875 - Loss: 0.1077",
    "Epoch 9/20 - Batch 1200/1875 - Loss: 0.0697",
    "Epoch 9/20 - Batch 1300/1875 - Loss: 0.0013",
    "Epoch 9/20 - Batch 1400/1875 - Loss: 0.0015",
    "Epoch 9/20 - Batch 1500/1875 - Loss: 0.1291",
    "Epoch 9/20 - Batch 1600/1875 - Loss: 0.0200",
    "Epoch 9/20 - Batch 1700/1875 - Loss: 0.0028",
    "Epoch 9/20 - Batch 1800/1875 - Loss: 0.0119",
    "Epoch 9 completed - Train Acc: 98.50% - Val Acc: 97.69%",
    "Epoch 10/20 - Batch 0/1875 - Loss: 0.0066",
    "Epoch 10/20 - Batch 100/1875 - Loss: 0.0073",
    "Epoch 10/20 - Batch 200/1875 - Loss: 0.0221",
    "Epoch 10/20 - Batch 300/1875 - Loss: 0.0011",
    "Epoch 10/20 - Batch 400/1875 - Loss: 0.1081",
    "Epoch 10/20 - Batch 500/1875 - Loss: 0.0370",
    "Epoch 10/20 - Batch 600/1875 - Loss: 0.0883",
    "Epoch 10/20 - Batch 700/1875 - Loss: 0.0187",
    "Epoch 10/20 - Batch 800/1875 - Loss: 0.0065",
    "Epoch 10/20 - Batch 900/1875 - Loss: 0.0012",
    "Epoch 10/20 - Batch 1000/1875 - Loss: 0.0028",
    "Epoch 10/20 - Batch 1100/1875 - Loss: 0.0354",
    "Epoch 10/20 - Batch 1200/1875 - Loss: 0.0184",
    "Epoch 10/20 - Batch 1300/1875 - Loss: 0.0011",
    "Epoch 10/20 - Batch 1400/1875 - Loss: 0.0194",
    "Epoch 10/20 - Batch 1500/1875 - Loss: 0.0084",
    "Epoch 10/20 - Batch 1600/1875 - Loss: 0.0075",
    "Epoch 10/20 - Batch 1700/1875 - Loss: 0.0492",
    "Epoch 10/20 - Batch 1800/1875 - Loss: 0.0194",
    "Epoch 10 completed - Train Acc: 98.57% - Val Acc: 97.93%",
    "Epoch 11/20 - Batch 0/1875 - Loss: 0.1411",
    "Epoch 11/20 - Batch 100/1875 - Loss: 0.0343",
    "Epoch 11/20 - Batch 200/1875 - Loss: 0.0012",
    "Epoch 11/20 - Batch 300/1875 - Loss: 0.0299",
    "Epoch 11/20 - Batch 400/1875 - Loss: 0.0162",
    "Epoch 11/20 - Batch 500/1875 - Loss: 0.0258",
    "Epoch 11/20 - Batch 600/1875 - Loss: 0.0050",
    "Epoch 11/20 - Batch 700/1875 - Loss: 0.0062",
    "Epoch 11/20 - Batch 800/1875 - Loss: 0.0435",
    "Epoch 11/20 - Batch 900/1875 - Loss: 0.0189",
    "Epoch 11/20 - Batch 1000/1875 - Loss: 0.0051",
    "Epoch 11/20 - Batch 1100/1875 - Loss: 0.1453",
    "Epoch 11/20 - Batch 1200/1875 - Loss: 0.0001",
    "Epoch 11/20 - Batch 1300/1875 - Loss: 0.0026",
    "Epoch 11/20 - Batch 1400/1875 - Loss: 0.0008",
    "Epoch 11/20 - Batch 1500/1875 - Loss: 0.2496",
    "Epoch 11/20 - Batch 1600/1875 - Loss: 0.0080",
    "Epoch 11/20 - Batch 1700/1875 - Loss: 0.0032",
    "Epoch 11/20 - Batch 1800/1875 - Loss: 0.0398",
    "Epoch 11 completed - Train Acc: 98.64% - Val Acc: 97.72%",
    "Epoch 12/20 - Batch 0/1875 - Loss: 0.0207",
    "Epoch 12/20 - Batch 100/1875 - Loss: 0.0083",
    "Epoch 12/20 - Batch 200/1875 - Loss: 0.0042",
    "Epoch 12/20 - Batch 300/1875 - Loss: 0.0044",
    "Epoch 12/20 - Batch 400/1875 - Loss: 0.0022",
    "Epoch 12/20 - Batch 500/1875 - Loss: 0.0409",
    "Epoch 12/20 - Batch 600/1875 - Loss: 0.0044",
    "Epoch 12/20 - Batch 700/1875 - Loss: 0.0009",
    "Epoch 12/20 - Batch 800/1875 - Loss: 0.0276",
    "Epoch 12/20 - Batch 900/1875 - Loss: 0.0058",
    "Epoch 12/20 - Batch 1000/1875 - Loss: 0.0037",
    "Epoch 12/20 - Batch 1100/1875 - Loss: 0.0256",
    "Epoch 12/20 - Batch 1200/1875 - Loss: 0.0002",
    "Epoch 12/20 - Batch 1300/1875 - Loss: 0.0232",
    "Epoch 12/20 - Batch 1400/1875 - Loss: 0.0275",
    "Epoch 12/20 - Batch 1500/1875 - Loss: 0.0081",
    "Epoch 12/20 - Batch 1600/1875 - Loss: 0.0073",
    "Epoch 12/20 - Batch 1700/1875 - Loss: 0.0876",
    "Epoch 12/20 - Batch 1800/1875 - Loss: 0.0239",
    "Epoch 12 completed - Train Acc: 98.70% - Val Acc: 97.41%",
    "Epoch 13/20 - Batch 0/1875 - Loss: 0.0042",
    "Epoch 13/20 - Batch 100/1875 - Loss: 0.0222",
    "Epoch 13/20 - Batch 200/1875 - Loss: 0.0137",
    "Epoch 13/20 - Batch 300/1875 - Loss: 0.0025",
    "Epoch 13/20 - Batch 400/1875 - Loss: 0.0018",
    "Epoch 13/20 - Batch 500/1875 - Loss: 0.0477",
    "Epoch 13/20 - Batch 600/1875 - Loss: 0.0580",
    "Epoch 13/20 - Batch 700/1875 - Loss: 0.0194",
    "Epoch 13/20 - Batch 800/1875 - Loss: 0.1688",
    "Epoch 13/20 - Batch 900/1875 - Loss: 0.0079",
    "Epoch 13/20 - Batch 1000/1875 - Loss: 0.1535",
    "Epoch 13/20 - Batch 1100/1875 - Loss: 0.0949",
    "Epoch 13/20 - Batch 1200/1875 - Loss: 0.1046",
    "Epoch 13/20 - Batch 1300/1875 - Loss: 0.0160",
    "Epoch 13/20 - Batch 1400/1875 - Loss: 0.0589",
    "Epoch 13/20 - Batch 1500/1875 - Loss: 0.0046",
    "Epoch 13/20 - Batch 1600/1875 - Loss: 0.2235",
    "Epoch 13/20 - Batch 1700/1875 - Loss: 0.1572",
    "Epoch 13/20 - Batch 1800/1875 - Loss: 0.0263",
    "Epoch 13 completed - Train Acc: 98.76% - Val Acc: 97.66%",
    "Epoch 14/20 - Batch 0/1875 - Loss: 0.0419",
    "Epoch 14/20 - Batch 100/1875 - Loss: 0.0227",
    "Epoch 14/20 - Batch 200/1875 - Loss: 0.0051",
    "Epoch 14/20 - Batch 300/1875 - Loss: 0.0035",
    "Epoch 14/20 - Batch 400/1875 - Loss: 0.1399",
    "Epoch 14/20 - Batch 500/1875 - Loss: 0.0035",
    "Epoch 14/20 - Batch 600/1875 - Loss: 0.0004",
    "Epoch 14/20 - Batch 700/1875 - Loss: 0.0157",
    "Epoch 14/20 - Batch 800/1875 - Loss: 0.0034",
    "Epoch 14/20 - Batch 900/1875 - Loss: 0.0049",
    "Epoch 14/20 - Batch 1000/1875 - Loss: 0.0612",
    "Epoch 14/20 - Batch 1100/1875 - Loss: 0.0078",
    "Epoch 14/20 - Batch 1200/1875 - Loss: 0.0007",
    "Epoch 14/20 - Batch 1300/1875 - Loss: 0.0142",
    "Epoch 14/20 - Batch 1400/1875 - Loss: 0.0089",
    "Epoch 14/20 - Batch 1500/1875 - Loss: 0.0178",
    "Epoch 14/20 - Batch 1600/1875 - Loss: 0.0054",
    "Epoch 14/20 - Batch 1700/1875 - Loss: 0.0387",
    "Epoch 14/20 - Batch 1800/1875 - Loss: 0.0141",
    "Epoch 14 completed - Train Acc: 98.81% - Val Acc: 97.88%",
    "Epoch 15/20 - Batch 0/1875 - Loss: 0.0014",
    "Epoch 15/20 - Batch 100/1875 - Loss: 0.3901",
    "Epoch 15/20 - Batch 200/1875 - Loss: 0.0010",
    "Epoch 15/20 - Batch 300/1875 - Loss: 0.0033",
    "Epoch 15/20 - Batch 400/1875 - Loss: 0.0532",
    "Epoch 15/20 - Batch 500/1875 - Loss: 0.0023",
    "Epoch 15/20 - Batch 600/1875 - Loss: 0.0107",
    "Epoch 15/20 - Batch 700/1875 - Loss: 0.0043",
    "Epoch 15/20 - Batch 800/1875 - Loss: 0.1120",
    "Epoch 15/20 - Batch 900/1875 - Loss: 0.0002",
    "Epoch 15/20 - Batch 1000/1875 - Loss: 0.0061",
    "Epoch 15/20 - Batch 1100/1875 - Loss: 0.0000",
    "Epoch 15/20 - Batch 1200/1875 - Loss: 0.0004",
    "Epoch 15/20 - Batch 1300/1875 - Loss: 0.0766",
    "Epoch 15/20 - Batch 1400/1875 - Loss: 0.0012",
    "Epoch 15/20 - Batch 1500/1875 - Loss: 0.0137",
    "Epoch 15/20 - Batch 1600/1875 - Loss: 0.1780",
    "Epoch 15/20 - Batch 1700/1875 - Loss: 0.0259",
    "Epoch 15/20 - Batch 1800/1875 - Loss: 0.0011",
    "Epoch 15 completed - Train Acc: 98.81% - Val Acc: 97.47%",
    "Epoch 16/20 - Batch 0/1875 - Loss: 0.0017",
    "Epoch 16/20 - Batch 100/1875 - Loss: 0.1074",
    "Epoch 16/20 - Batch 200/1875 - Loss: 0.0004",
    "Epoch 16/20 - Batch 300/1875 - Loss: 0.0849",
    "Epoch 16/20 - Batch 400/1875 - Loss: 0.0659",
    "Epoch 16/20 - Batch 500/1875 - Loss: 0.0049",
    "Epoch 16/20 - Batch 600/1875 - Loss: 0.0255",
    "Epoch 16/20 - Batch 700/1875 - Loss: 0.0023",
    "Epoch 16/20 - Batch 800/1875 - Loss: 0.0019",
    "Epoch 16/20 - Batch 900/1875 - Loss: 0.1487",
    "Epoch 16/20 - Batch 1000/1875 - Loss: 0.0279",
    "Epoch 16/20 - Batch 1100/1875 - Loss: 0.0440",
    "Epoch 16/20 - Batch 1200/1875 - Loss: 0.0003",
    "Epoch 16/20 - Batch 1300/1875 - Loss: 0.0112",
    "Epoch 16/20 - Batch 1400/1875 - Loss: 0.0269",
    "Epoch 16/20 - Batch 1500/1875 - Loss: 0.0021",
    "Epoch 16/20 - Batch 1600/1875 - Loss: 0.1374",
    "Epoch 16/20 - Batch 1700/1875 - Loss: 0.0018",
    "Epoch 16/20 - Batch 1800/1875 - Loss: 0.1029",
    "Epoch 16 completed - Train Acc: 98.88% - Val Acc: 97.83%",
    "Epoch 17/20 - Batch 0/1875 - Loss: 0.0070",
    "Epoch 17/20 - Batch 100/1875 - Loss: 0.0507",
    "Epoch 17/20 - Batch 200/1875 - Loss: 0.0325",
    "Epoch 17/20 - Batch 300/1875 - Loss: 0.0148",
    "Epoch 17/20 - Batch 400/1875 - Loss: 0.0455",
    "Epoch 17/20 - Batch 500/1875 - Loss: 0.0113",
    "Epoch 17/20 - Batch 600/1875 - Loss: 0.0004",
    "Epoch 17/20 - Batch 700/1875 - Loss: 0.0445",
    "Epoch 17/20 - Batch 800/1875 - Loss: 0.0308",
    "Epoch 17/20 - Batch 900/1875 - Loss: 0.1798",
    "Epoch 17/20 - Batch 1000/1875 - Loss: 0.0067",
    "Epoch 17/20 - Batch 1100/1875 - Loss: 0.0149",
    "Epoch 17/20 - Batch 1200/1875 - Loss: 0.0164",
    "Epoch 17/20 - Batch 1300/1875 - Loss: 0.1081",
    "Epoch 17/20 - Batch 1400/1875 - Loss: 0.0003",
    "Epoch 17/20 - Batch 1500/1875 - Loss: 0.0908",
    "Epoch 17/20 - Batch 1600/1875 - Loss: 0.0359",
    "Epoch 17/20 - Batch 1700/1875 - Loss: 0.0243",
    "Epoch 17/20 - Batch 1800/1875 - Loss: 0.0878",
    "Epoch 17 completed - Train Acc: 98.90% - Val Acc: 97.95%",
    "Epoch 18/20 - Batch 0/1875 - Loss: 0.0166",
    "Epoch 18/20 - Batch 100/1875 - Loss: 0.0015",
    "Epoch 18/20 - Batch 200/1875 - Loss: 0.0005",
    "Epoch 18/20 - Batch 300/1875 - Loss: 0.0032",
    "Epoch 18/20 - Batch 400/1875 - Loss: 0.0280",
    "Epoch 18/20 - Batch 500/1875 - Loss: 0.0014",
    "Epoch 18/20 - Batch 600/1875 - Loss: 0.0106",
    "Epoch 18/20 - Batch 700/1875 - Loss: 0.0006",
    "Epoch 18/20 - Batch 800/1875 - Loss: 0.0010",
    "Epoch 18/20 - Batch 900/1875 - Loss: 0.0226",
    "Epoch 18/20 - Batch 1000/1875 - Loss: 0.0072",
    "Epoch 18/20 - Batch 1100/1875 - Loss: 0.0169",
    "Epoch 18/20 - Batch 1200/1875 - Loss: 0.0100",
    "Epoch 18/20 - Batch 1300/1875 - Loss: 0.0066",
    "Epoch 18/20 - Batch 1400/1875 - Loss: 0.0021",
    "Epoch 18/20 - Batch 1500/1875 - Loss: 0.0351",
    "Epoch 18/20 - Batch 1600/1875 - Loss: 0.0117",
    "Epoch 18/20 - Batch 1700/1875 - Loss: 0.0068",
    "Epoch 18/20 - Batch 1800/1875 - Loss: 0.0023",
    "Epoch 18 completed - Train Acc: 98.86% - Val Acc: 96.71%",
    "Epoch 19/20 - Batch 0/1875 - Loss: 0.1797",
    "Epoch 19/20 - Batch 100/1875 - Loss: 0.2720",
    "Epoch 19/20 - Batch 200/1875 - Loss: 0.0107",
    "Epoch 19/20 - Batch 300/1875 - Loss: 0.0115",
    "Epoch 19/20 - Batch 400/1875 - Loss: 0.0942",
    "Epoch 19/20 - Batch 500/1875 - Loss: 0.0019",
    "Epoch 19/20 - Batch 600/1875 - Loss: 0.0067",
    "Epoch 19/20 - Batch 700/1875 - Loss: 0.0344",
    "Epoch 19/20 - Batch 800/1875 - Loss: 0.0011",
    "Epoch 19/20 - Batch 900/1875 - Loss: 0.0048",
    "Epoch 19/20 - Batch 1000/1875 - Loss: 0.4783",
    "Epoch 19/20 - Batch 1100/1875 - Loss: 0.0011",
    "Epoch 19/20 - Batch 1200/1875 - Loss: 0.0078",
    "Epoch 19/20 - Batch 1300/1875 - Loss: 0.1019",
    "Epoch 19/20 - Batch 1400/1875 - Loss: 0.1349",
    "Epoch 19/20 - Batch 1500/1875 - Loss: 0.0159",
    "Epoch 19/20 - Batch 1600/1875 - Loss: 0.0285",
    "Epoch 19/20 - Batch 1700/1875 - Loss: 0.0296",
    "Epoch 19/20 - Batch 1800/1875 - Loss: 0.0027",
    "Epoch 19 completed - Train Acc: 98.86% - Val Acc: 97.75%",
    "Epoch 20/20 - Batch 0/1875 - Loss: 0.0495",
    "Epoch 20/20 - Batch 100/1875 - Loss: 0.0056",
    "Epoch 20/20 - Batch 200/1875 - Loss: 0.0019",
    "Epoch 20/20 - Batch 300/1875 - Loss: 0.0192",
    "Epoch 20/20 - Batch 400/1875 - Loss: 0.0049",
    "Epoch 20/20 - Batch 500/1875 - Loss: 0.0013",
    "Epoch 20/20 - Batch 600/1875 - Loss: 0.0015",
    "Epoch 20/20 - Batch 700/1875 - Loss: 0.1057",
    "Epoch 20/20 - Batch 800/1875 - Loss: 0.0061",
    "Epoch 20/20 - Batch 900/1875 - Loss: 0.0064",
    "Epoch 20/20 - Batch 1000/1875 - Loss: 0.0013",
    "Epoch 20/20 - Batch 1100/1875 - Loss: 0.0161",
    "Epoch 20/20 - Batch 1200/1875 - Loss: 0.0006",
    "Epoch 20/20 - Batch 1300/1875 - Loss: 0.1155",
    "Epoch 20/20 - Batch 1400/1875 - Loss: 0.0014",
    "Epoch 20/20 - Batch 1500/1875 - Loss: 0.0122",
    "Epoch 20/20 - Batch 1600/1875 - Loss: 0.0859",
    "Epoch 20/20 - Batch 1700/1875 - Loss: 0.0099",
    "Epoch 20/20 - Batch 1800/1875 - Loss: 0.0005",
    "Epoch 20 completed - Train Acc: 98.93% - Val Acc: 97.97%",
    "Training completed. Model saved to models/ZPE-QuantumWeaver-V1.pt"
  ],
  "metrics": [
    {
      "epoch": 1,
      "train_loss": 0.2678156571038067,
      "train_accuracy": 91.965,
      "val_loss": 0.14492810547229842,
      "val_accuracy": 95.91
    },
    {
      "epoch": 2,
      "train_loss": 0.13007636189622185,
      "train_accuracy": 96.36333333333333,
      "val_loss": 0.15576262715642308,
      "val_accuracy": 95.51
    },
    {
      "epoch": 3,
      "train_loss": 0.10149086504836256,
      "train_accuracy": 97.22333333333333,
      "val_loss": 0.11538307295661024,
      "val_accuracy": 96.82
    },
    {
      "epoch": 4,
      "train_loss": 0.08717029067271699,
      "train_accuracy": 97.57,
      "val_loss": 0.09520046316223374,
      "val_accuracy": 97.48
    },
    {
      "epoch": 5,
      "train_loss": 0.07382915352714092,
      "train_accuracy": 97.93666666666667,
      "val_loss": 0.12906584320855832,
      "val_accuracy": 96.81
    },
    {
      "epoch": 6,
      "train_loss": 0.06425276160756281,
      "train_accuracy": 98.16166666666666,
      "val_loss": 0.09560721632251822,
      "val_accuracy": 97.61
    },
    {
      "epoch": 7,
      "train_loss": 0.06055192689626322,
      "train_accuracy": 98.28833333333333,
      "val_loss": 0.10361013720608672,
      "val_accuracy": 97.38
    },
    {
      "epoch": 8,
      "train_loss": 0.054189399556827264,
      "train_accuracy": 98.36333333333333,
      "val_loss": 0.10749612583530718,
      "val_accuracy": 97.22
    },
    {
      "epoch": 9,
      "train_loss": 0.05117676881528847,
      "train_accuracy": 98.505,
      "val_loss": 0.0919804139117483,
      "val_accuracy": 97.69
    },
    {
      "epoch": 10,
      "train_loss": 0.048489589729410365,
      "train_accuracy": 98.57333333333334,
      "val_loss": 0.08258334030125725,
      "val_accuracy": 97.93
    },
    {
      "epoch": 11,
      "train_loss": 0.04622291741016088,
      "train_accuracy": 98.64,
      "val_loss": 0.08389346291426246,
      "val_accuracy": 97.72
    },
    {
      "epoch": 12,
      "train_loss": 0.04416318250685581,
      "train_accuracy": 98.7,
      "val_loss": 0.1099265787117602,
      "val_accuracy": 97.41
    },
    {
      "epoch": 13,
      "train_loss": 0.04163093430627972,
      "train_accuracy": 98.76166666666667,
      "val_loss": 0.09070211381090491,
      "val_accuracy": 97.66
    },
    {
      "epoch": 14,
      "train_loss": 0.041180549511680146,
      "train_accuracy": 98.80666666666667,
      "val_loss": 0.0775775039400499,
      "val_accuracy": 97.88
    },
    {
      "epoch": 15,
      "train_loss": 0.0401170850796431,
      "train_accuracy": 98.81166666666667,
      "val_loss": 0.088416027775333,
      "val_accuracy": 97.47
    },
    {
      "epoch": 16,
      "train_loss": 0.038656588160438696,
      "train_accuracy": 98.87666666666667,
      "val_loss": 0.10098918590328425,
      "val_accuracy": 97.83
    },
    {
      "epoch": 17,
      "train_loss": 0.03620319781647801,
      "train_accuracy": 98.89833333333333,
      "val_loss": 0.08251034930764564,
      "val_accuracy": 97.95
    },
    {
      "epoch": 18,
      "train_loss": 0.03738063182653471,
      "train_accuracy": 98.855,
      "val_loss": 0.13130681223505722,
      "val_accuracy": 96.71
    },
    {
      "epoch": 19,
      "train_loss": 0.037930345723067874,
      "train_accuracy": 98.85666666666667,
      "val_loss": 0.08746671221577187,
      "val_accuracy": 97.75
    },
    {
      "epoch": 20,
      "train_loss": 0.034746336892781254,
      "train_accuracy": 98.92666666666666,
      "val_loss": 0.07496630919691312,
      "val_accuracy": 97.97
    }
  ]
}