{
  "job_id": "zpe_job_1779938b",
  "status": "completed",
  "parameters": {
    "modelName": "ZPE-QuantumWeaver-V1",
    "totalEpochs": 20,
    "batchSize": 32,
    "learningRate": 0.0011,
    "weightDecay": 0.0001,
    "momentumParams": [
      0.91,
      0.91,
      0.91,
      0.91,
      0.91,
      0.91
    ],
    "strengthParams": [
      0.09,
      0.09,
      0.09,
      0.09,
      0.09,
      0.09
    ],
    "noiseParams": [
      0.011,
      0.011,
      0.011,
      0.011,
      0.011,
      0.011
    ],
    "couplingParams": [
      0.11,
      0.11,
      0.11,
      0.11,
      0.11,
      0.08
    ],
    "quantumCircuitSize": 32,
    "labelSmoothing": 0.1,
    "quantumMode": true,
    "baseConfigId": "zpe_job_d243fa84",
    "mixupAlpha": 0.2
  },
  "start_time": "2025-06-20T05:05:17.436Z",
  "log_messages": [
    "Using device: cuda",
    "Datasets loaded successfully",
    "Model initialized",
    "Epoch 1/20 - Batch 0/1875 - Loss: 2.3059",
    "Epoch 1/20 - Batch 100/1875 - Loss: 0.5194",
    "Epoch 1/20 - Batch 200/1875 - Loss: 0.4899",
    "Epoch 1/20 - Batch 300/1875 - Loss: 0.0747",
    "Epoch 1/20 - Batch 400/1875 - Loss: 0.0852",
    "Epoch 1/20 - Batch 500/1875 - Loss: 0.2472",
    "Epoch 1/20 - Batch 600/1875 - Loss: 0.2004",
    "Epoch 1/20 - Batch 700/1875 - Loss: 0.2182",
    "Epoch 1/20 - Batch 800/1875 - Loss: 0.3218",
    "Epoch 1/20 - Batch 900/1875 - Loss: 0.1967",
    "Epoch 1/20 - Batch 1000/1875 - Loss: 0.1879",
    "Epoch 1/20 - Batch 1100/1875 - Loss: 0.0353",
    "Epoch 1/20 - Batch 1200/1875 - Loss: 0.3812",
    "Epoch 1/20 - Batch 1300/1875 - Loss: 0.1245",
    "Epoch 1/20 - Batch 1400/1875 - Loss: 0.1549",
    "Epoch 1/20 - Batch 1500/1875 - Loss: 0.0164",
    "Epoch 1/20 - Batch 1600/1875 - Loss: 0.2464",
    "Epoch 1/20 - Batch 1700/1875 - Loss: 0.0865",
    "Epoch 1/20 - Batch 1800/1875 - Loss: 0.0288",
    "Epoch 1 completed - Train Acc: 91.64% - Val Acc: 96.10%",
    "Epoch 2/20 - Batch 0/1875 - Loss: 0.0637",
    "Epoch 2/20 - Batch 100/1875 - Loss: 0.1820",
    "Epoch 2/20 - Batch 200/1875 - Loss: 0.0595",
    "Epoch 2/20 - Batch 300/1875 - Loss: 0.0891",
    "Epoch 2/20 - Batch 400/1875 - Loss: 0.1775",
    "Epoch 2/20 - Batch 500/1875 - Loss: 0.0073",
    "Epoch 2/20 - Batch 600/1875 - Loss: 0.1055",
    "Epoch 2/20 - Batch 700/1875 - Loss: 0.0903",
    "Epoch 2/20 - Batch 800/1875 - Loss: 0.1691",
    "Epoch 2/20 - Batch 900/1875 - Loss: 0.2118",
    "Epoch 2/20 - Batch 1000/1875 - Loss: 0.1096",
    "Epoch 2/20 - Batch 1100/1875 - Loss: 0.2467",
    "Epoch 2/20 - Batch 1200/1875 - Loss: 0.1370",
    "Epoch 2/20 - Batch 1300/1875 - Loss: 0.1333",
    "Epoch 2/20 - Batch 1400/1875 - Loss: 0.0528",
    "Epoch 2/20 - Batch 1500/1875 - Loss: 0.0561",
    "Epoch 2/20 - Batch 1600/1875 - Loss: 0.0075",
    "Epoch 2/20 - Batch 1700/1875 - Loss: 0.0387",
    "Epoch 2/20 - Batch 1800/1875 - Loss: 0.2915",
    "Epoch 2 completed - Train Acc: 96.39% - Val Acc: 96.53%",
    "Epoch 3/20 - Batch 0/1875 - Loss: 0.3717",
    "Epoch 3/20 - Batch 100/1875 - Loss: 0.0636",
    "Epoch 3/20 - Batch 200/1875 - Loss: 0.1281",
    "Epoch 3/20 - Batch 300/1875 - Loss: 0.0162",
    "Epoch 3/20 - Batch 400/1875 - Loss: 0.1099",
    "Epoch 3/20 - Batch 500/1875 - Loss: 0.0112",
    "Epoch 3/20 - Batch 600/1875 - Loss: 0.1936",
    "Epoch 3/20 - Batch 700/1875 - Loss: 0.0451",
    "Epoch 3/20 - Batch 800/1875 - Loss: 0.0605",
    "Epoch 3/20 - Batch 900/1875 - Loss: 0.0868",
    "Epoch 3/20 - Batch 1000/1875 - Loss: 0.2995",
    "Epoch 3/20 - Batch 1100/1875 - Loss: 0.1090",
    "Epoch 3/20 - Batch 1200/1875 - Loss: 0.0466",
    "Epoch 3/20 - Batch 1300/1875 - Loss: 0.0862",
    "Epoch 3/20 - Batch 1400/1875 - Loss: 0.0216",
    "Epoch 3/20 - Batch 1500/1875 - Loss: 0.2866",
    "Epoch 3/20 - Batch 1600/1875 - Loss: 0.0328",
    "Epoch 3/20 - Batch 1700/1875 - Loss: 0.0167",
    "Epoch 3/20 - Batch 1800/1875 - Loss: 0.0445",
    "Epoch 3 completed - Train Acc: 97.21% - Val Acc: 97.17%",
    "Epoch 4/20 - Batch 0/1875 - Loss: 0.0150",
    "Epoch 4/20 - Batch 100/1875 - Loss: 0.0091",
    "Epoch 4/20 - Batch 200/1875 - Loss: 0.0282",
    "Epoch 4/20 - Batch 300/1875 - Loss: 0.0875",
    "Epoch 4/20 - Batch 400/1875 - Loss: 0.1471",
    "Epoch 4/20 - Batch 500/1875 - Loss: 0.0291",
    "Epoch 4/20 - Batch 600/1875 - Loss: 0.1032",
    "Epoch 4/20 - Batch 700/1875 - Loss: 0.0344",
    "Epoch 4/20 - Batch 800/1875 - Loss: 0.0345",
    "Epoch 4/20 - Batch 900/1875 - Loss: 0.1274",
    "Epoch 4/20 - Batch 1000/1875 - Loss: 0.1118",
    "Epoch 4/20 - Batch 1100/1875 - Loss: 0.1971",
    "Epoch 4/20 - Batch 1200/1875 - Loss: 0.0079",
    "Epoch 4/20 - Batch 1300/1875 - Loss: 0.0088",
    "Epoch 4/20 - Batch 1400/1875 - Loss: 0.0046",
    "Epoch 4/20 - Batch 1500/1875 - Loss: 0.0702",
    "Epoch 4/20 - Batch 1600/1875 - Loss: 0.0039",
    "Epoch 4/20 - Batch 1700/1875 - Loss: 0.0588",
    "Epoch 4/20 - Batch 1800/1875 - Loss: 0.0121",
    "Epoch 4 completed - Train Acc: 97.70% - Val Acc: 96.86%",
    "Epoch 5/20 - Batch 0/1875 - Loss: 0.0031",
    "Epoch 5/20 - Batch 100/1875 - Loss: 0.0543",
    "Epoch 5/20 - Batch 200/1875 - Loss: 0.0885",
    "Epoch 5/20 - Batch 300/1875 - Loss: 0.0656",
    "Epoch 5/20 - Batch 400/1875 - Loss: 0.0574",
    "Epoch 5/20 - Batch 500/1875 - Loss: 0.1564",
    "Epoch 5/20 - Batch 600/1875 - Loss: 0.0003",
    "Epoch 5/20 - Batch 700/1875 - Loss: 0.0037",
    "Epoch 5/20 - Batch 800/1875 - Loss: 0.0995",
    "Epoch 5/20 - Batch 900/1875 - Loss: 0.0067",
    "Epoch 5/20 - Batch 1000/1875 - Loss: 0.0808",
    "Epoch 5/20 - Batch 1100/1875 - Loss: 0.0125",
    "Epoch 5/20 - Batch 1200/1875 - Loss: 0.0085",
    "Epoch 5/20 - Batch 1300/1875 - Loss: 0.2492",
    "Epoch 5/20 - Batch 1400/1875 - Loss: 0.0270",
    "Epoch 5/20 - Batch 1500/1875 - Loss: 0.0226",
    "Epoch 5/20 - Batch 1600/1875 - Loss: 0.0922",
    "Epoch 5/20 - Batch 1700/1875 - Loss: 0.0154",
    "Epoch 5/20 - Batch 1800/1875 - Loss: 0.0714",
    "Epoch 5 completed - Train Acc: 97.93% - Val Acc: 97.14%",
    "Epoch 6/20 - Batch 0/1875 - Loss: 0.0381",
    "Epoch 6/20 - Batch 100/1875 - Loss: 0.0241",
    "Epoch 6/20 - Batch 200/1875 - Loss: 0.1462",
    "Epoch 6/20 - Batch 300/1875 - Loss: 0.0739",
    "Epoch 6/20 - Batch 400/1875 - Loss: 0.0836",
    "Epoch 6/20 - Batch 500/1875 - Loss: 0.0729",
    "Epoch 6/20 - Batch 600/1875 - Loss: 0.0036",
    "Epoch 6/20 - Batch 700/1875 - Loss: 0.0945",
    "Epoch 6/20 - Batch 800/1875 - Loss: 0.0066",
    "Epoch 6/20 - Batch 900/1875 - Loss: 0.0070",
    "Epoch 6/20 - Batch 1000/1875 - Loss: 0.0058",
    "Epoch 6/20 - Batch 1100/1875 - Loss: 0.2854",
    "Epoch 6/20 - Batch 1200/1875 - Loss: 0.0738",
    "Epoch 6/20 - Batch 1300/1875 - Loss: 0.0983",
    "Epoch 6/20 - Batch 1400/1875 - Loss: 0.0587",
    "Epoch 6/20 - Batch 1500/1875 - Loss: 0.0549",
    "Epoch 6/20 - Batch 1600/1875 - Loss: 0.0084",
    "Epoch 6/20 - Batch 1700/1875 - Loss: 0.1082",
    "Epoch 6/20 - Batch 1800/1875 - Loss: 0.0638",
    "Epoch 6 completed - Train Acc: 98.17% - Val Acc: 97.67%",
    "Epoch 7/20 - Batch 0/1875 - Loss: 0.0023",
    "Epoch 7/20 - Batch 100/1875 - Loss: 0.0008",
    "Epoch 7/20 - Batch 200/1875 - Loss: 0.1928",
    "Epoch 7/20 - Batch 300/1875 - Loss: 0.0223",
    "Epoch 7/20 - Batch 400/1875 - Loss: 0.0088",
    "Epoch 7/20 - Batch 500/1875 - Loss: 0.0153",
    "Epoch 7/20 - Batch 600/1875 - Loss: 0.0076",
    "Epoch 7/20 - Batch 700/1875 - Loss: 0.0923",
    "Epoch 7/20 - Batch 800/1875 - Loss: 0.0345",
    "Epoch 7/20 - Batch 900/1875 - Loss: 0.1544",
    "Epoch 7/20 - Batch 1000/1875 - Loss: 0.0180",
    "Epoch 7/20 - Batch 1100/1875 - Loss: 0.0234",
    "Epoch 7/20 - Batch 1200/1875 - Loss: 0.0016",
    "Epoch 7/20 - Batch 1300/1875 - Loss: 0.0841",
    "Epoch 7/20 - Batch 1400/1875 - Loss: 0.0805",
    "Epoch 7/20 - Batch 1500/1875 - Loss: 0.0383",
    "Epoch 7/20 - Batch 1600/1875 - Loss: 0.0355",
    "Epoch 7/20 - Batch 1700/1875 - Loss: 0.0023",
    "Epoch 7/20 - Batch 1800/1875 - Loss: 0.0611",
    "Epoch 7 completed - Train Acc: 98.23% - Val Acc: 96.26%",
    "Epoch 8/20 - Batch 0/1875 - Loss: 0.1216",
    "Epoch 8/20 - Batch 100/1875 - Loss: 0.1545",
    "Epoch 8/20 - Batch 200/1875 - Loss: 0.1184",
    "Epoch 8/20 - Batch 300/1875 - Loss: 0.0131",
    "Epoch 8/20 - Batch 400/1875 - Loss: 0.0035",
    "Epoch 8/20 - Batch 500/1875 - Loss: 0.0488",
    "Epoch 8/20 - Batch 600/1875 - Loss: 0.0127",
    "Epoch 8/20 - Batch 700/1875 - Loss: 0.0329",
    "Epoch 8/20 - Batch 800/1875 - Loss: 0.1756",
    "Epoch 8/20 - Batch 900/1875 - Loss: 0.0011",
    "Epoch 8/20 - Batch 1000/1875 - Loss: 0.2093",
    "Epoch 8/20 - Batch 1100/1875 - Loss: 0.0385",
    "Epoch 8/20 - Batch 1200/1875 - Loss: 0.0846",
    "Epoch 8/20 - Batch 1300/1875 - Loss: 0.0157",
    "Epoch 8/20 - Batch 1400/1875 - Loss: 0.1474",
    "Epoch 8/20 - Batch 1500/1875 - Loss: 0.0100",
    "Epoch 8/20 - Batch 1600/1875 - Loss: 0.0183",
    "Epoch 8/20 - Batch 1700/1875 - Loss: 0.4067",
    "Epoch 8/20 - Batch 1800/1875 - Loss: 0.2783",
    "Epoch 8 completed - Train Acc: 98.41% - Val Acc: 97.65%",
    "Epoch 9/20 - Batch 0/1875 - Loss: 0.0182",
    "Epoch 9/20 - Batch 100/1875 - Loss: 0.0119",
    "Epoch 9/20 - Batch 200/1875 - Loss: 0.0104",
    "Epoch 9/20 - Batch 300/1875 - Loss: 0.0420",
    "Epoch 9/20 - Batch 400/1875 - Loss: 0.0826",
    "Epoch 9/20 - Batch 500/1875 - Loss: 0.0394",
    "Epoch 9/20 - Batch 600/1875 - Loss: 0.0154",
    "Epoch 9/20 - Batch 700/1875 - Loss: 0.0302",
    "Epoch 9/20 - Batch 800/1875 - Loss: 0.0358",
    "Epoch 9/20 - Batch 900/1875 - Loss: 0.1352",
    "Epoch 9/20 - Batch 1000/1875 - Loss: 0.0400",
    "Epoch 9/20 - Batch 1100/1875 - Loss: 0.1824",
    "Epoch 9/20 - Batch 1200/1875 - Loss: 0.0247",
    "Epoch 9/20 - Batch 1300/1875 - Loss: 0.0677",
    "Epoch 9/20 - Batch 1400/1875 - Loss: 0.0090",
    "Epoch 9/20 - Batch 1500/1875 - Loss: 0.0059",
    "Epoch 9/20 - Batch 1600/1875 - Loss: 0.0529",
    "Epoch 9/20 - Batch 1700/1875 - Loss: 0.0170",
    "Epoch 9/20 - Batch 1800/1875 - Loss: 0.0020",
    "Epoch 9 completed - Train Acc: 98.44% - Val Acc: 97.83%",
    "Epoch 10/20 - Batch 0/1875 - Loss: 0.0069",
    "Epoch 10/20 - Batch 100/1875 - Loss: 0.0446",
    "Epoch 10/20 - Batch 200/1875 - Loss: 0.0038",
    "Epoch 10/20 - Batch 300/1875 - Loss: 0.0046",
    "Epoch 10/20 - Batch 400/1875 - Loss: 0.0275",
    "Epoch 10/20 - Batch 500/1875 - Loss: 0.0080",
    "Epoch 10/20 - Batch 600/1875 - Loss: 0.0664",
    "Epoch 10/20 - Batch 700/1875 - Loss: 0.0018",
    "Epoch 10/20 - Batch 800/1875 - Loss: 0.0013",
    "Epoch 10/20 - Batch 900/1875 - Loss: 0.0145",
    "Epoch 10/20 - Batch 1000/1875 - Loss: 0.0010",
    "Epoch 10/20 - Batch 1100/1875 - Loss: 0.0013",
    "Epoch 10/20 - Batch 1200/1875 - Loss: 0.0133",
    "Epoch 10/20 - Batch 1300/1875 - Loss: 0.0075",
    "Epoch 10/20 - Batch 1400/1875 - Loss: 0.0590",
    "Epoch 10/20 - Batch 1500/1875 - Loss: 0.0060",
    "Epoch 10/20 - Batch 1600/1875 - Loss: 0.0031",
    "Epoch 10/20 - Batch 1700/1875 - Loss: 0.0026",
    "Epoch 10/20 - Batch 1800/1875 - Loss: 0.0349",
    "Epoch 10 completed - Train Acc: 98.59% - Val Acc: 97.68%",
    "Epoch 11/20 - Batch 0/1875 - Loss: 0.0125",
    "Epoch 11/20 - Batch 100/1875 - Loss: 0.0002",
    "Epoch 11/20 - Batch 200/1875 - Loss: 0.0039",
    "Epoch 11/20 - Batch 300/1875 - Loss: 0.0063",
    "Epoch 11/20 - Batch 400/1875 - Loss: 0.0012",
    "Epoch 11/20 - Batch 500/1875 - Loss: 0.0014",
    "Epoch 11/20 - Batch 600/1875 - Loss: 0.0689",
    "Epoch 11/20 - Batch 700/1875 - Loss: 0.0063",
    "Epoch 11/20 - Batch 800/1875 - Loss: 0.0164",
    "Epoch 11/20 - Batch 900/1875 - Loss: 0.0021",
    "Epoch 11/20 - Batch 1000/1875 - Loss: 0.0030",
    "Epoch 11/20 - Batch 1100/1875 - Loss: 0.1577",
    "Epoch 11/20 - Batch 1200/1875 - Loss: 0.1309",
    "Epoch 11/20 - Batch 1300/1875 - Loss: 0.0003",
    "Epoch 11/20 - Batch 1400/1875 - Loss: 0.0158",
    "Epoch 11/20 - Batch 1500/1875 - Loss: 0.0065",
    "Epoch 11/20 - Batch 1600/1875 - Loss: 0.0145",
    "Epoch 11/20 - Batch 1700/1875 - Loss: 0.0256",
    "Epoch 11/20 - Batch 1800/1875 - Loss: 0.0080",
    "Epoch 11 completed - Train Acc: 98.65% - Val Acc: 97.77%",
    "Epoch 12/20 - Batch 0/1875 - Loss: 0.0037",
    "Epoch 12/20 - Batch 100/1875 - Loss: 0.0006",
    "Epoch 12/20 - Batch 200/1875 - Loss: 0.1187",
    "Epoch 12/20 - Batch 300/1875 - Loss: 0.0034",
    "Epoch 12/20 - Batch 400/1875 - Loss: 0.0680",
    "Epoch 12/20 - Batch 500/1875 - Loss: 0.0073",
    "Epoch 12/20 - Batch 600/1875 - Loss: 0.0314",
    "Epoch 12/20 - Batch 700/1875 - Loss: 0.0190",
    "Epoch 12/20 - Batch 800/1875 - Loss: 0.0257",
    "Epoch 12/20 - Batch 900/1875 - Loss: 0.0418",
    "Epoch 12/20 - Batch 1000/1875 - Loss: 0.0062",
    "Epoch 12/20 - Batch 1100/1875 - Loss: 0.0035",
    "Epoch 12/20 - Batch 1200/1875 - Loss: 0.0013",
    "Epoch 12/20 - Batch 1300/1875 - Loss: 0.0150",
    "Epoch 12/20 - Batch 1400/1875 - Loss: 0.0357",
    "Epoch 12/20 - Batch 1500/1875 - Loss: 0.0057",
    "Epoch 12/20 - Batch 1600/1875 - Loss: 0.0334",
    "Epoch 12/20 - Batch 1700/1875 - Loss: 0.0010",
    "Epoch 12/20 - Batch 1800/1875 - Loss: 0.0033",
    "Epoch 12 completed - Train Acc: 98.68% - Val Acc: 97.58%",
    "Epoch 13/20 - Batch 0/1875 - Loss: 0.1671",
    "Epoch 13/20 - Batch 100/1875 - Loss: 0.0014",
    "Epoch 13/20 - Batch 200/1875 - Loss: 0.0168",
    "Epoch 13/20 - Batch 300/1875 - Loss: 0.0040",
    "Epoch 13/20 - Batch 400/1875 - Loss: 0.0007",
    "Epoch 13/20 - Batch 500/1875 - Loss: 0.0030",
    "Epoch 13/20 - Batch 600/1875 - Loss: 0.0027",
    "Epoch 13/20 - Batch 700/1875 - Loss: 0.0100",
    "Epoch 13/20 - Batch 800/1875 - Loss: 0.0048",
    "Epoch 13/20 - Batch 900/1875 - Loss: 0.0114",
    "Epoch 13/20 - Batch 1000/1875 - Loss: 0.2070",
    "Epoch 13/20 - Batch 1100/1875 - Loss: 0.4070",
    "Epoch 13/20 - Batch 1200/1875 - Loss: 0.0406",
    "Epoch 13/20 - Batch 1300/1875 - Loss: 0.0065",
    "Epoch 13/20 - Batch 1400/1875 - Loss: 0.1125",
    "Epoch 13/20 - Batch 1500/1875 - Loss: 0.0876",
    "Epoch 13/20 - Batch 1600/1875 - Loss: 0.0078",
    "Epoch 13/20 - Batch 1700/1875 - Loss: 0.0178",
    "Epoch 13/20 - Batch 1800/1875 - Loss: 0.0429",
    "Epoch 13 completed - Train Acc: 98.73% - Val Acc: 97.36%",
    "Epoch 14/20 - Batch 0/1875 - Loss: 0.0474",
    "Epoch 14/20 - Batch 100/1875 - Loss: 0.0061",
    "Epoch 14/20 - Batch 200/1875 - Loss: 0.0834",
    "Epoch 14/20 - Batch 300/1875 - Loss: 0.0012",
    "Epoch 14/20 - Batch 400/1875 - Loss: 0.0159",
    "Epoch 14/20 - Batch 500/1875 - Loss: 0.0629",
    "Epoch 14/20 - Batch 600/1875 - Loss: 0.0097",
    "Epoch 14/20 - Batch 700/1875 - Loss: 0.0962",
    "Epoch 14/20 - Batch 800/1875 - Loss: 0.1491",
    "Epoch 14/20 - Batch 900/1875 - Loss: 0.0003",
    "Epoch 14/20 - Batch 1000/1875 - Loss: 0.0008",
    "Epoch 14/20 - Batch 1100/1875 - Loss: 0.0014",
    "Epoch 14/20 - Batch 1200/1875 - Loss: 0.0332",
    "Epoch 14/20 - Batch 1300/1875 - Loss: 0.0334",
    "Epoch 14/20 - Batch 1400/1875 - Loss: 0.0010",
    "Epoch 14/20 - Batch 1500/1875 - Loss: 0.0032",
    "Epoch 14/20 - Batch 1600/1875 - Loss: 0.0022",
    "Epoch 14/20 - Batch 1700/1875 - Loss: 0.0043",
    "Epoch 14/20 - Batch 1800/1875 - Loss: 0.0342",
    "Epoch 14 completed - Train Acc: 98.80% - Val Acc: 96.99%",
    "Epoch 15/20 - Batch 0/1875 - Loss: 0.0939",
    "Epoch 15/20 - Batch 100/1875 - Loss: 0.0069",
    "Epoch 15/20 - Batch 200/1875 - Loss: 0.0015",
    "Epoch 15/20 - Batch 300/1875 - Loss: 0.0094",
    "Epoch 15/20 - Batch 400/1875 - Loss: 0.0038",
    "Epoch 15/20 - Batch 500/1875 - Loss: 0.0027",
    "Epoch 15/20 - Batch 600/1875 - Loss: 0.0566",
    "Epoch 15/20 - Batch 700/1875 - Loss: 0.0009",
    "Epoch 15/20 - Batch 800/1875 - Loss: 0.0050",
    "Epoch 15/20 - Batch 900/1875 - Loss: 0.0007",
    "Epoch 15/20 - Batch 1000/1875 - Loss: 0.0112",
    "Epoch 15/20 - Batch 1100/1875 - Loss: 0.3656",
    "Epoch 15/20 - Batch 1200/1875 - Loss: 0.0151",
    "Epoch 15/20 - Batch 1300/1875 - Loss: 0.0045",
    "Epoch 15/20 - Batch 1400/1875 - Loss: 0.0174",
    "Epoch 15/20 - Batch 1500/1875 - Loss: 0.0020",
    "Epoch 15/20 - Batch 1600/1875 - Loss: 0.0441",
    "Epoch 15/20 - Batch 1700/1875 - Loss: 0.0238",
    "Epoch 15/20 - Batch 1800/1875 - Loss: 0.0053",
    "Epoch 15 completed - Train Acc: 98.72% - Val Acc: 97.60%",
    "Epoch 16/20 - Batch 0/1875 - Loss: 0.0323",
    "Epoch 16/20 - Batch 100/1875 - Loss: 0.0021",
    "Epoch 16/20 - Batch 200/1875 - Loss: 0.0023",
    "Epoch 16/20 - Batch 300/1875 - Loss: 0.0013",
    "Epoch 16/20 - Batch 400/1875 - Loss: 0.3164",
    "Epoch 16/20 - Batch 500/1875 - Loss: 0.0432",
    "Epoch 16/20 - Batch 600/1875 - Loss: 0.0117",
    "Epoch 16/20 - Batch 700/1875 - Loss: 0.1869",
    "Epoch 16/20 - Batch 800/1875 - Loss: 0.0702",
    "Epoch 16/20 - Batch 900/1875 - Loss: 0.2293",
    "Epoch 16/20 - Batch 1000/1875 - Loss: 0.0300",
    "Epoch 16/20 - Batch 1100/1875 - Loss: 0.0526",
    "Epoch 16/20 - Batch 1200/1875 - Loss: 0.0000",
    "Epoch 16/20 - Batch 1300/1875 - Loss: 0.0027",
    "Epoch 16/20 - Batch 1400/1875 - Loss: 0.0023",
    "Epoch 16/20 - Batch 1500/1875 - Loss: 0.0007",
    "Epoch 16/20 - Batch 1600/1875 - Loss: 0.0164",
    "Epoch 16/20 - Batch 1700/1875 - Loss: 0.0041",
    "Epoch 16/20 - Batch 1800/1875 - Loss: 0.0151",
    "Epoch 16 completed - Train Acc: 98.84% - Val Acc: 97.92%",
    "Epoch 17/20 - Batch 0/1875 - Loss: 0.0008",
    "Epoch 17/20 - Batch 100/1875 - Loss: 0.0050",
    "Epoch 17/20 - Batch 200/1875 - Loss: 0.0010",
    "Epoch 17/20 - Batch 300/1875 - Loss: 0.0069",
    "Epoch 17/20 - Batch 400/1875 - Loss: 0.0014",
    "Epoch 17/20 - Batch 500/1875 - Loss: 0.0019",
    "Epoch 17/20 - Batch 600/1875 - Loss: 0.0006",
    "Epoch 17/20 - Batch 700/1875 - Loss: 0.0617",
    "Epoch 17/20 - Batch 800/1875 - Loss: 0.0146",
    "Epoch 17/20 - Batch 900/1875 - Loss: 0.0336",
    "Epoch 17/20 - Batch 1000/1875 - Loss: 0.0190",
    "Epoch 17/20 - Batch 1100/1875 - Loss: 0.0926",
    "Epoch 17/20 - Batch 1200/1875 - Loss: 0.0017",
    "Epoch 17/20 - Batch 1300/1875 - Loss: 0.0009",
    "Epoch 17/20 - Batch 1400/1875 - Loss: 0.0058",
    "Epoch 17/20 - Batch 1500/1875 - Loss: 0.0313",
    "Epoch 17/20 - Batch 1600/1875 - Loss: 0.2861",
    "Epoch 17/20 - Batch 1700/1875 - Loss: 0.0018",
    "Epoch 17/20 - Batch 1800/1875 - Loss: 0.0277",
    "Epoch 17 completed - Train Acc: 98.88% - Val Acc: 97.45%",
    "Epoch 18/20 - Batch 0/1875 - Loss: 0.0252",
    "Epoch 18/20 - Batch 100/1875 - Loss: 0.0030",
    "Epoch 18/20 - Batch 200/1875 - Loss: 0.0037",
    "Epoch 18/20 - Batch 300/1875 - Loss: 0.0008",
    "Epoch 18/20 - Batch 400/1875 - Loss: 0.2957",
    "Epoch 18/20 - Batch 500/1875 - Loss: 0.0008",
    "Epoch 18/20 - Batch 600/1875 - Loss: 0.0244",
    "Epoch 18/20 - Batch 700/1875 - Loss: 0.0407",
    "Epoch 18/20 - Batch 800/1875 - Loss: 0.0037",
    "Epoch 18/20 - Batch 900/1875 - Loss: 0.0094",
    "Epoch 18/20 - Batch 1000/1875 - Loss: 0.0065",
    "Epoch 18/20 - Batch 1100/1875 - Loss: 0.0260",
    "Epoch 18/20 - Batch 1200/1875 - Loss: 0.0021",
    "Epoch 18/20 - Batch 1300/1875 - Loss: 0.0927",
    "Epoch 18/20 - Batch 1400/1875 - Loss: 0.0018",
    "Epoch 18/20 - Batch 1500/1875 - Loss: 0.0047",
    "Epoch 18/20 - Batch 1600/1875 - Loss: 0.0037",
    "Epoch 18/20 - Batch 1700/1875 - Loss: 0.0007",
    "Epoch 18/20 - Batch 1800/1875 - Loss: 0.0250",
    "Epoch 18 completed - Train Acc: 98.94% - Val Acc: 97.90%",
    "Epoch 19/20 - Batch 0/1875 - Loss: 0.0333",
    "Epoch 19/20 - Batch 100/1875 - Loss: 0.0513",
    "Epoch 19/20 - Batch 200/1875 - Loss: 0.0055",
    "Epoch 19/20 - Batch 300/1875 - Loss: 0.0028",
    "Epoch 19/20 - Batch 400/1875 - Loss: 0.0466",
    "Epoch 19/20 - Batch 500/1875 - Loss: 0.0012",
    "Epoch 19/20 - Batch 600/1875 - Loss: 0.0406",
    "Epoch 19/20 - Batch 700/1875 - Loss: 0.0406",
    "Epoch 19/20 - Batch 800/1875 - Loss: 0.0041",
    "Epoch 19/20 - Batch 900/1875 - Loss: 0.0014",
    "Epoch 19/20 - Batch 1000/1875 - Loss: 0.0261",
    "Epoch 19/20 - Batch 1100/1875 - Loss: 0.2018",
    "Epoch 19/20 - Batch 1200/1875 - Loss: 0.1202",
    "Epoch 19/20 - Batch 1300/1875 - Loss: 0.0137",
    "Epoch 19/20 - Batch 1400/1875 - Loss: 0.0908",
    "Epoch 19/20 - Batch 1500/1875 - Loss: 0.0837",
    "Epoch 19/20 - Batch 1600/1875 - Loss: 0.0078",
    "Epoch 19/20 - Batch 1700/1875 - Loss: 0.0683",
    "Epoch 19/20 - Batch 1800/1875 - Loss: 0.0016",
    "Epoch 19 completed - Train Acc: 98.89% - Val Acc: 96.97%",
    "Epoch 20/20 - Batch 0/1875 - Loss: 0.0182",
    "Epoch 20/20 - Batch 100/1875 - Loss: 0.0308",
    "Epoch 20/20 - Batch 200/1875 - Loss: 0.0157",
    "Epoch 20/20 - Batch 300/1875 - Loss: 0.0004",
    "Epoch 20/20 - Batch 400/1875 - Loss: 0.0005",
    "Epoch 20/20 - Batch 500/1875 - Loss: 0.0677",
    "Epoch 20/20 - Batch 600/1875 - Loss: 0.0004",
    "Epoch 20/20 - Batch 700/1875 - Loss: 0.0019",
    "Epoch 20/20 - Batch 800/1875 - Loss: 0.0118",
    "Epoch 20/20 - Batch 900/1875 - Loss: 0.0457",
    "Epoch 20/20 - Batch 1000/1875 - Loss: 0.0013",
    "Epoch 20/20 - Batch 1100/1875 - Loss: 0.0274",
    "Epoch 20/20 - Batch 1200/1875 - Loss: 0.0036",
    "Epoch 20/20 - Batch 1300/1875 - Loss: 0.0162",
    "Epoch 20/20 - Batch 1400/1875 - Loss: 0.0991",
    "Epoch 20/20 - Batch 1500/1875 - Loss: 0.0012",
    "Epoch 20/20 - Batch 1600/1875 - Loss: 0.0352",
    "Epoch 20/20 - Batch 1700/1875 - Loss: 0.0018",
    "Epoch 20/20 - Batch 1800/1875 - Loss: 0.0053",
    "Epoch 20 completed - Train Acc: 98.88% - Val Acc: 97.54%",
    "Training completed. Model saved to models/ZPE-QuantumWeaver-V1.pt"
  ],
  "metrics": [
    {
      "epoch": 1,
      "train_loss": 0.27792743443747364,
      "train_accuracy": 91.645,
      "val_loss": 0.1350829306939325,
      "val_accuracy": 96.1
    },
    {
      "epoch": 2,
      "train_loss": 0.12922498475685715,
      "train_accuracy": 96.395,
      "val_loss": 0.1303238188883233,
      "val_accuracy": 96.53
    },
    {
      "epoch": 3,
      "train_loss": 0.10222597012543119,
      "train_accuracy": 97.21,
      "val_loss": 0.10800687824764599,
      "val_accuracy": 97.17
    },
    {
      "epoch": 4,
      "train_loss": 0.08300685698051627,
      "train_accuracy": 97.705,
      "val_loss": 0.11633968675553402,
      "val_accuracy": 96.86
    },
    {
      "epoch": 5,
      "train_loss": 0.07310488063161416,
      "train_accuracy": 97.92666666666666,
      "val_loss": 0.11275383260278167,
      "val_accuracy": 97.14
    },
    {
      "epoch": 6,
      "train_loss": 0.06485665282478634,
      "train_accuracy": 98.175,
      "val_loss": 0.08851880325953727,
      "val_accuracy": 97.67
    },
    {
      "epoch": 7,
      "train_loss": 0.06146286197254279,
      "train_accuracy": 98.23,
      "val_loss": 0.13439438527319045,
      "val_accuracy": 96.26
    },
    {
      "epoch": 8,
      "train_loss": 0.05651500050526423,
      "train_accuracy": 98.41333333333333,
      "val_loss": 0.08183104870478272,
      "val_accuracy": 97.65
    },
    {
      "epoch": 9,
      "train_loss": 0.05471138509041048,
      "train_accuracy": 98.435,
      "val_loss": 0.0848097615805938,
      "val_accuracy": 97.83
    },
    {
      "epoch": 10,
      "train_loss": 0.04831192068955085,
      "train_accuracy": 98.595,
      "val_loss": 0.09113363701736364,
      "val_accuracy": 97.68
    },
    {
      "epoch": 11,
      "train_loss": 0.04502691251438422,
      "train_accuracy": 98.65166666666667,
      "val_loss": 0.08819736723800536,
      "val_accuracy": 97.77
    },
    {
      "epoch": 12,
      "train_loss": 0.04633919941936862,
      "train_accuracy": 98.68166666666667,
      "val_loss": 0.09845502685286668,
      "val_accuracy": 97.58
    },
    {
      "epoch": 13,
      "train_loss": 0.04341514265187143,
      "train_accuracy": 98.73333333333333,
      "val_loss": 0.1080749700585338,
      "val_accuracy": 97.36
    },
    {
      "epoch": 14,
      "train_loss": 0.04189327005788024,
      "train_accuracy": 98.79833333333333,
      "val_loss": 0.11539295326735464,
      "val_accuracy": 96.99
    },
    {
      "epoch": 15,
      "train_loss": 0.042661683934086855,
      "train_accuracy": 98.72,
      "val_loss": 0.09483065350898727,
      "val_accuracy": 97.6
    },
    {
      "epoch": 16,
      "train_loss": 0.039730473333311964,
      "train_accuracy": 98.84166666666667,
      "val_loss": 0.0841841423660897,
      "val_accuracy": 97.92
    },
    {
      "epoch": 17,
      "train_loss": 0.03665538989297347,
      "train_accuracy": 98.88166666666666,
      "val_loss": 0.10003831254598423,
      "val_accuracy": 97.45
    },
    {
      "epoch": 18,
      "train_loss": 0.03726763373032445,
      "train_accuracy": 98.935,
      "val_loss": 0.0826499384613864,
      "val_accuracy": 97.9
    },
    {
      "epoch": 19,
      "train_loss": 0.036986853976431304,
      "train_accuracy": 98.88666666666667,
      "val_loss": 0.1236830696859648,
      "val_accuracy": 96.97
    },
    {
      "epoch": 20,
      "train_loss": 0.035850115671242626,
      "train_accuracy": 98.88333333333334,
      "val_loss": 0.11290401834777147,
      "val_accuracy": 97.54
    }
  ]
}